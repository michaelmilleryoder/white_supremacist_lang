
  0%|                                                                                | 0/778326 [00:00<?, ?it/s]You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/home/mamille3/white_supremacist_lang/conda_env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '

























































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































  4%|██▌                                                            | 32000/778326 [1:14:38<37:57:19,  5.46it/s]The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: word_count, dataset, text, source, timestamp, domain, id. If word_count, dataset, text, source, timestamp, domain, id are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 922457
  Batch size = 32
  0%|                                                                        | 21/28827 [00:01<25:09, 19.08it/s]


































































































































































































































































































































































































































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████| 28827/28827 [23:34<00:00, 23.78it/s]

Configuration saved in ../output/bert/checkpoint-32000/config.json
Model weights saved in ../output/bert/checkpoint-32000/pytorch_model.bin
tokenizer config file saved in ../output/bert/checkpoint-32000/tokenizer_config.json
Special tokens file saved in ../output/bert/checkpoint-32000/special_tokens_map.json
/home/mamille3/white_supremacist_lang/conda_env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '















































































































































































































































































































































































