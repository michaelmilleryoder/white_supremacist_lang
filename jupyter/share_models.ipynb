{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ba12df2-769c-4b10-be92-bb17f80d6886",
   "metadata": {},
   "source": [
    "# Test applying a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a17f223f-93dd-4256-a01b-38473b02151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_dirpath = '/home/mamille3/white_supremacist_lang/output/bert/6topic_annotated_5x/checkpoint-21210'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dirpath)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3bc6df7-3c4e-45ec-9b63-b650e1fc8745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run example data through (preprocess, get output)\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "example_data = [ # taken from Alatawi+2021 annotated dataset\n",
    "    'of course this is happening to one of your elite white male appointees for decades the radical left has been marching through the educational system with hatred for everything white historically western while flooding the west with new voters they are trying to overthrow us',\n",
    "    'africans and asians are not projected to be minorities in their countries why do you support this happening to whites',\n",
    "    'happy birthday king',\n",
    "    'it ok went back to normal',\n",
    "]\n",
    "\n",
    "inputs = tokenizer(example_data, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "output = model(**inputs) # these are logits\n",
    "\n",
    "# Convert logits to binary predictions\n",
    "preds = torch.argmax(output.logits, dim=1)\n",
    "preds\n",
    "# Convert it to a numpy array\n",
    "preds.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964c53db-5865-40a5-88ac-ab8cf4d2d452",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a4235af1-77dd-4d35-8e56-edf34c7197af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = data.query('predicted == \"white_supremacist\" and label==1')\n",
    "len(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e500792-b48b-4de3-940e-76626793123f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alatawi2021_588</th>\n",
       "      <td>it ok went back to normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1949</th>\n",
       "      <td>believe scientists refer to it as the jay double virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1069</th>\n",
       "      <td>angus taylor must be removed from his energy portfolio he has been total failure when he was given it he said he would get elect prices down with his big stick that was years ago and all we have got from him is stalling tactics sackthebastered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1509</th>\n",
       "      <td>in 1940 my 20 year old future mother rode the trolley to downtown st paul mn to see the picture show nights per week after 1965 however women stopped going out at night it was safer to stay home and watch tv this loss of women freedom ought to be regretted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1232</th>\n",
       "      <td>where do they make these creatures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_486</th>\n",
       "      <td>thank you for calling this out look up terry bean and dennis hastert there are more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_553</th>\n",
       "      <td>just one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_288</th>\n",
       "      <td>happy birthday king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1037</th>\n",
       "      <td>often wonder when the second coming of christ will be but it seems merely waiting on damn cat to move</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1025</th>\n",
       "      <td>aware the left looks at compromise as an opening but they will try to ban semi autos large capacity mags they ll want the 20 30 rd ones but we can point to heller say nope these are in common use we can not say that about 100 rd ones so why not win some good pr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                   text\n",
       "id                                                                                                                                                                                                                                                                                     \n",
       "alatawi2021_588                                                                                                                                                                                                                                               it ok went back to normal\n",
       "alatawi2021_1949                                                                                                                                                                                                                 believe scientists refer to it as the jay double virus\n",
       "alatawi2021_1069                    angus taylor must be removed from his energy portfolio he has been total failure when he was given it he said he would get elect prices down with his big stick that was years ago and all we have got from him is stalling tactics sackthebastered\n",
       "alatawi2021_1509       in 1940 my 20 year old future mother rode the trolley to downtown st paul mn to see the picture show nights per week after 1965 however women stopped going out at night it was safer to stay home and watch tv this loss of women freedom ought to be regretted\n",
       "alatawi2021_1232                                                                                                                                                                                                                                     where do they make these creatures\n",
       "alatawi2021_486                                                                                                                                                                                     thank you for calling this out look up terry bean and dennis hastert there are more\n",
       "alatawi2021_553                                                                                                                                                                                                                                                                just one\n",
       "alatawi2021_288                                                                                                                                                                                                                                                     happy birthday king\n",
       "alatawi2021_1037                                                                                                                                                                  often wonder when the second coming of christ will be but it seems merely waiting on damn cat to move\n",
       "alatawi2021_1025  aware the left looks at compromise as an opening but they will try to ban semi autos large capacity mags they ll want the 20 30 rd ones but we can point to heller say nope these are in common use we can not say that about 100 rd ones so why not win some good pr"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_ws = data.query('predicted == \"neutral\" and label==0')\n",
    "not_ws.sample(10)[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db65c944-ded3-4bc1-88fe-7759c74ae546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alatawi2021_630</th>\n",
       "      <td>firstly he did not make children do anything he merely rewarded them if they did fight secondly anti whites use children as political soldiers every day in white western nations so could not possibly care less what they say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_182</th>\n",
       "      <td>of course this is happening to one of your elite white male appointees for decades the radical left has been marching through the educational system with hatred for everything white historically western while flooding the west with new voters they are trying to overthrow us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1405</th>\n",
       "      <td>you can document illegals because the system is broken your fellow congressional members have had decades to correct it their plan was all along to let it get to this point and open the flood gates not on my watch too many illegal criminals already getting in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_309</th>\n",
       "      <td>part of frederick the great jewish policy part in frederick correspondence jews appear as currency manipulating financiers as wartime merchants as spies used by both sides and as the unwanted residents of conquered territories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_18</th>\n",
       "      <td>25 000 fake child refugees in france cost 800 million per year via</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_438</th>\n",
       "      <td>africans and asians are not projected to be minorities in their countries why do you support this happening to whites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_469</th>\n",
       "      <td>sweden tyrannic invader resettlement law being used to eliminate homogeneous white areas via</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1970</th>\n",
       "      <td>the fraud of feminism 1913 by bax ernest belfort 1854 1926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_103</th>\n",
       "      <td>there reason they say one death is tragedy one million is statistic it part and parcel of living in society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_652</th>\n",
       "      <td>yes this is not hidden fact that hitler helped in part to send jews to palestine indirectly helping to create the stage of israel but why should that matter he obviously was doing it because it got the jews out of germany with all parties being fine not because he was shill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                text\n",
       "id                                                                                                                                                                                                                                                                                                  \n",
       "alatawi2021_630                                                      firstly he did not make children do anything he merely rewarded them if they did fight secondly anti whites use children as political soldiers every day in white western nations so could not possibly care less what they say\n",
       "alatawi2021_182   of course this is happening to one of your elite white male appointees for decades the radical left has been marching through the educational system with hatred for everything white historically western while flooding the west with new voters they are trying to overthrow us\n",
       "alatawi2021_1405                 you can document illegals because the system is broken your fellow congressional members have had decades to correct it their plan was all along to let it get to this point and open the flood gates not on my watch too many illegal criminals already getting in\n",
       "alatawi2021_309                                                   part of frederick the great jewish policy part in frederick correspondence jews appear as currency manipulating financiers as wartime merchants as spies used by both sides and as the unwanted residents of conquered territories\n",
       "alatawi2021_18                                                                                                                                                                                                                    25 000 fake child refugees in france cost 800 million per year via\n",
       "alatawi2021_438                                                                                                                                                                africans and asians are not projected to be minorities in their countries why do you support this happening to whites\n",
       "alatawi2021_469                                                                                                                                                                                         sweden tyrannic invader resettlement law being used to eliminate homogeneous white areas via\n",
       "alatawi2021_1970                                                                                                                                                                                                                          the fraud of feminism 1913 by bax ernest belfort 1854 1926\n",
       "alatawi2021_103                                                                                                                                                                          there reason they say one death is tragedy one million is statistic it part and parcel of living in society\n",
       "alatawi2021_652   yes this is not hidden fact that hitler helped in part to send jews to palestine indirectly helping to create the stage of israel but why should that matter he obviously was doing it because it got the jews out of germany with all parties being fine not because he was shill"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.sample(10)[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b46e0435-1abc-4209-b1ae-e95b17c6496a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alatawi2021_788</th>\n",
       "      <td>congrats destroying isis just he said he would real leader get it done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1970</th>\n",
       "      <td>the fraud of feminism 1913 by bax ernest belfort 1854 1926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_309</th>\n",
       "      <td>part of frederick the great jewish policy part in frederick correspondence jews appear as currency manipulating financiers as wartime merchants as spies used by both sides and as the unwanted residents of conquered territories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1964</th>\n",
       "      <td>there term for those that call your existence privilege your continued existence supremacy that cheer on your demographic replacement and push for it every chance they get that try to erase your history and take future away from your children enemies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1548</th>\n",
       "      <td>trashy show for trashy people they make the trash look bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_911</th>\n",
       "      <td>those are the self interested conservative types who will never be on board until we already have successful organizations up and running talking about getting to that point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1650</th>\n",
       "      <td>all mass shootings are eventually turned into fake amp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_778</th>\n",
       "      <td>trump prosecutes his own white supporters for defending themselves from antifa ambushes but earnestly pleads the case for black rappers promoting crude violence and filth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1007</th>\n",
       "      <td>it can be starting point to explain that differences in outcomes between races has better explanation than white exploitation whites care for fairness and this will allow them to see the differences as fair other than that it is not important for our cause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1988</th>\n",
       "      <td>hebrew immigrant aid society again demands us take in refugees but not in israel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                              text\n",
       "id                                                                                                                                                                                                                                                                                \n",
       "alatawi2021_788                                                                                                                                                                                             congrats destroying isis just he said he would real leader get it done\n",
       "alatawi2021_1970                                                                                                                                                                                                        the fraud of feminism 1913 by bax ernest belfort 1854 1926\n",
       "alatawi2021_309                                 part of frederick the great jewish policy part in frederick correspondence jews appear as currency manipulating financiers as wartime merchants as spies used by both sides and as the unwanted residents of conquered territories\n",
       "alatawi2021_1964        there term for those that call your existence privilege your continued existence supremacy that cheer on your demographic replacement and push for it every chance they get that try to erase your history and take future away from your children enemies\n",
       "alatawi2021_1548                                                                                                                                                                                                        trashy show for trashy people they make the trash look bad\n",
       "alatawi2021_911                                                                                      those are the self interested conservative types who will never be on board until we already have successful organizations up and running talking about getting to that point\n",
       "alatawi2021_1650                                                                                                                                                                                                            all mass shootings are eventually turned into fake amp\n",
       "alatawi2021_778                                                                                         trump prosecutes his own white supporters for defending themselves from antifa ambushes but earnestly pleads the case for black rappers promoting crude violence and filth\n",
       "alatawi2021_1007  it can be starting point to explain that differences in outcomes between races has better explanation than white exploitation whites care for fairness and this will allow them to see the differences as fair other than that it is not important for our cause\n",
       "alatawi2021_1988                                                                                                                                                                                  hebrew immigrant aid society again demands us take in refugees but not in israel"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pred_ws.sample(10)[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd26d971-339b-487d-9d4a-89e2d8f2203b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this flower smells really nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>white genocide is real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text\n",
       "0  this flower smells really nice\n",
       "1          white genocide is real"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess text and apply tokenizer\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "example_data = [ # taken from annotated datasets\n",
    "    'this flower smells really nice',\n",
    "    'white genocide is real',\n",
    "]\n",
    "example_df = pd.DataFrame({'text': example_data})\n",
    "example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eaeb46e6-3a8b-4672-b051-fcb1148ce70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4436fd31194537b913ade1c595342e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(df):\n",
    "    return tokenizer(df[\"text\"], truncation=True)\n",
    "\n",
    "dataset = Dataset.from_pandas(pred_ws)\n",
    "tokenized = dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d37ebc5-814a-47b2-985a-0ac6aeac140a",
   "metadata": {},
   "source": [
    "## Classify (as just a PyTorch Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b0dbcca9-bdbf-4f6f-89e0-66cbbe369cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the muslim thug needed some 00 buck where it counts'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ws.iloc[1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "265d3b8a-9c7f-4f3b-8f08-055cca6bf833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-1.7837,  1.9144]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs = tokenizer(example_data[0], return_tensors='pt')\n",
    "# inputs = tokenizer(example_data[1], return_tensors='pt')\n",
    "# inputs = tokenizer(example_data[2], return_tensors='pt')\n",
    "# inputs = tokenizer(example_data[3], return_tensors='pt')\n",
    "inputs = tokenizer(pred_ws.iloc[3]['text'], return_tensors='pt')\n",
    "# Should do for multiple examples (map it to the list)\n",
    "# inputs = list(map(tokenizer(example_data, return_tensors='pt')\n",
    "output = model(**inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "33d8cb2e-97fd-42df-9638-0729d9eb1b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary predictions\n",
    "# import numpy as np\n",
    "import torch\n",
    "\n",
    "# preds = np.argmax(output.logits, axis=-1)\n",
    "preds = torch.argmax(output.logits, dim=1)\n",
    "# preds = torch.argmax(output.logits)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08979b2-3ea4-440f-9ba5-084b5aa38397",
   "metadata": {},
   "source": [
    "## Classify (with Trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f9a4ff7-1ae7-49bb-8875-d8d80be14051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "\n",
    "args = TrainingArguments(\n",
    "           logging_dir='logs',\n",
    "           output_dir='output',\n",
    "           learning_rate=2e-5,\n",
    "           per_device_train_batch_size = 16,\n",
    "           per_device_eval_batch_size = 16,\n",
    "           num_train_epochs=1,\n",
    "           weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = args,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    # compute_metrics = self.compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb8afb33-924d-4640-ae78-dee949813c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 4\n",
      "  Batch size = 32\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "output = trainer.predict(tokenized)\n",
    "\n",
    "# Binary predictions\n",
    "preds = np.argmax(output.predictions, axis=-1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "065148b6-7f28-4c14-8815-d9b1bd9e6ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999845</td>\n",
       "      <td>0.000155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.981697</td>\n",
       "      <td>0.018303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999157</td>\n",
       "      <td>0.000843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998917</td>\n",
       "      <td>0.001083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.999845  0.000155\n",
       "1  0.981697  0.018303\n",
       "2  0.999157  0.000843\n",
       "3  0.998917  0.001083"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numeric class probability predictions\n",
    "import scipy\n",
    "\n",
    "prob = scipy.special.softmax(output.predictions, axis=-1)\n",
    "class_prob = pd.DataFrame(prob)\n",
    "class_prob\n",
    "# class_prob.columns = class_prob.columns.map(self.id2label)\n",
    "# class_prob.to_json(prob_outpath, orient='records', lines=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eadfb9-b345-4b5d-8e0a-a01d362da591",
   "metadata": {},
   "source": [
    "# Load some data that has been predicted as white supremacist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f942542a-58ea-405a-a3fc-df8055d69b0a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      white_supremacist\n",
       "1                neutral\n",
       "2      white_supremacist\n",
       "3                neutral\n",
       "4      white_supremacist\n",
       "             ...        \n",
       "576              neutral\n",
       "577    white_supremacist\n",
       "578    white_supremacist\n",
       "579              neutral\n",
       "580    white_supremacist\n",
       "Length: 581, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load predictions\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "exp_name = '6topic_annotated_5x_21210_test30'\n",
    "# preds_path = os.path.join('../output/bert/', exp_name, 'hatecheck_identity_nonhate_predictions.json')\n",
    "preds_path = os.path.join('../output/bert/', exp_name, 'alatawi2021_predictions.json')\n",
    "preds = pd.read_json(preds_path, typ='series')\n",
    "preds\n",
    "\n",
    "test_label_combine = {'antiracist': 'neutral'}\n",
    "if test_label_combine is not None:\n",
    "    preds = preds.map(lambda pred: test_label_combine.get(pred, pred))\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37eb223d-08e4-46a3-bd07-f69001446192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral              359\n",
       "white_supremacist    222\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "878a49b2-b6a1-4e3d-99fb-57ca2d077330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4011234/676251951.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['predicted'] = preds.values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predicted</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1717</th>\n",
       "      <td>we will do this using the magic of government ...</td>\n",
       "      <td>white_supremacist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1946</th>\n",
       "      <td>the muslim thug needed some 00 buck where it c...</td>\n",
       "      <td>white_supremacist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1132</th>\n",
       "      <td>over the course of 15 years or so ve talked to...</td>\n",
       "      <td>white_supremacist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_487</th>\n",
       "      <td>sorry bro no racism on the tl had to respond w...</td>\n",
       "      <td>white_supremacist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1732</th>\n",
       "      <td>watch what happened when this muslim lad inter...</td>\n",
       "      <td>white_supremacist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1485</th>\n",
       "      <td>ban the burqa wants burqas banned from governm...</td>\n",
       "      <td>white_supremacist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1504</th>\n",
       "      <td>2020 is definitely going to be national populi...</td>\n",
       "      <td>white_supremacist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_1706</th>\n",
       "      <td>notice how omits the role of iran regime and h...</td>\n",
       "      <td>white_supremacist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_732</th>\n",
       "      <td>you degenerate cultureless philistine your ins...</td>\n",
       "      <td>white_supremacist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_879</th>\n",
       "      <td>none of this crew has an iq even slightly high...</td>\n",
       "      <td>white_supremacist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               text  \\\n",
       "id                                                                    \n",
       "alatawi2021_1717  we will do this using the magic of government ...   \n",
       "alatawi2021_1946  the muslim thug needed some 00 buck where it c...   \n",
       "alatawi2021_1132  over the course of 15 years or so ve talked to...   \n",
       "alatawi2021_487   sorry bro no racism on the tl had to respond w...   \n",
       "alatawi2021_1732  watch what happened when this muslim lad inter...   \n",
       "...                                                             ...   \n",
       "alatawi2021_1485  ban the burqa wants burqas banned from governm...   \n",
       "alatawi2021_1504  2020 is definitely going to be national populi...   \n",
       "alatawi2021_1706  notice how omits the role of iran regime and h...   \n",
       "alatawi2021_732   you degenerate cultureless philistine your ins...   \n",
       "alatawi2021_879   none of this crew has an iq even slightly high...   \n",
       "\n",
       "                          predicted  label  \n",
       "id                                          \n",
       "alatawi2021_1717  white_supremacist      1  \n",
       "alatawi2021_1946  white_supremacist      1  \n",
       "alatawi2021_1132  white_supremacist      1  \n",
       "alatawi2021_487   white_supremacist      1  \n",
       "alatawi2021_1732  white_supremacist      1  \n",
       "...                             ...    ...  \n",
       "alatawi2021_1485  white_supremacist      1  \n",
       "alatawi2021_1504  white_supremacist      1  \n",
       "alatawi2021_1706  white_supremacist      0  \n",
       "alatawi2021_732   white_supremacist      1  \n",
       "alatawi2021_879   white_supremacist      1  \n",
       "\n",
       "[222 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data (Alatawi+2021 from annotated test30)\n",
    "corpus_path = '../tmp/annotated_corpus_test30.pkl'\n",
    "corpus = pd.read_pickle(corpus_path)\n",
    "data = corpus[corpus.dataset=='alatawi2021'].copy()\n",
    "# data.info()\n",
    "\n",
    "# data_path = '../data/alatawi2021_white_supremacist_annotated_tweets.csv'\n",
    "# data = pd.read_csv(data_path)\n",
    "# data['text'] = data['input.text'].map(tokenize_lowercase)\n",
    "# data['label'] = data['Voting and Final Labels']\n",
    "\n",
    "data['predicted'] = preds.values\n",
    "data[data['predicted']=='white_supremacist'][['text', 'predicted', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f2c2bff-4948-438a-9f1f-edef76e44ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ws = data[data['predicted']=='white_supremacist']\n",
    "len(pred_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "96dc33da-c9b2-4659-9d4e-2865ab327439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1b5d6e5f4545f9a24d337b42a9ead3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make sure these are predicted white supremacist\n",
    "\n",
    "def preprocess(df):\n",
    "    return tokenizer(df[\"text\"], truncation=True)\n",
    "\n",
    "dataset = Dataset.from_pandas(pred_ws)\n",
    "tokenized = dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0536661b-04e8-4b58-b3c3-9a7d4f3691d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: domain, source, id, word_count, predicted, text, dataset. If domain, source, id, word_count, predicted, text, dataset are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 222\n",
      "  Batch size = 32\n",
      "/home/mamille3/white_supremacist_lang/conda_env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "output = trainer.predict(tokenized)\n",
    "\n",
    "# Binary predictions\n",
    "preds = np.argmax(output.predictions, axis=-1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cec3872-98ce-455f-a0ba-d83c29ebbec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "762"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data (HateCheck)\n",
    "data_path = '../../data/hate_speech/hatecheck-data/test_suite_cases.csv'\n",
    "data = pd.read_csv(data_path, index_col=0)\n",
    "selected_identities = ['trans people', 'gay people', 'women',\n",
    "                'black people', 'Muslims', 'immigrants']\n",
    "selected_cols = ['ident_neutral_nh', 'ident_pos_nh',\n",
    "                'slur_homonym_nh', 'slur_reclaimed_nh',\n",
    "                'negate_neg_nh',\n",
    "                'counter_quote_nh', 'counter_ref_nh',\n",
    "                ]\n",
    "data = data.query('target_ident==@selected_identities and functionality==@selected_cols')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9da92692-3a17-4c63-9ace-f56b5ad780a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def tokenize_lowercase(inp, nlp=None):\n",
    "    \"\"\" Tokenize and lowercase text with NLTK \"\"\"\n",
    "    if nlp is not None:\n",
    "        tokens = [tok.text for tok in nlp.tokenizer(inp)]\n",
    "    else:\n",
    "        tokens = nltk.word_tokenize(str(inp))\n",
    "    return ' '.join(tokens).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7806f08b-c702-4370-a022-f168b2a671b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'test_case'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/white_supremacist_lang/conda_env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/white_supremacist_lang/conda_env/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/white_supremacist_lang/conda_env/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'test_case'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mword_tokenize(\u001b[38;5;28mstr\u001b[39m(inp))\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tokens)\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m---> 11\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_case\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmap(tokenize_lowercase)\n\u001b[1;32m     12\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_case\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m~/white_supremacist_lang/conda_env/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/white_supremacist_lang/conda_env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'test_case'"
     ]
    }
   ],
   "source": [
    "data['text'] = data['test_case'].map(tokenize_lowercase)\n",
    "data.head()[['text', 'test_case']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95ad1ba4-66ca-4c26-aa20-a4279a12eafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>she bought some faggots at the butcher .</td>\n",
       "      <td>white_supremacist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>calling myself a faggot to offend the homophob...</td>\n",
       "      <td>white_supremacist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>i 'm a proud faggot , and i should not be bann...</td>\n",
       "      <td>white_supremacist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>well , i am happily a faggot and proud !</td>\n",
       "      <td>white_supremacist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>happy pride month ! i love being a faggot !</td>\n",
       "      <td>white_supremacist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>there have to be consequences for saying you w...</td>\n",
       "      <td>white_supremacist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>why would you think it 's okay to call me a fa...</td>\n",
       "      <td>white_supremacist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>why would you think it 's okay to call me a ni...</td>\n",
       "      <td>white_supremacist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>why would you think it 's okay to call me a ra...</td>\n",
       "      <td>white_supremacist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>if you 're telling immigrants to go fuck thems...</td>\n",
       "      <td>white_supremacist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text          predicted\n",
       "985            she bought some faggots at the butcher .  white_supremacist\n",
       "1041  calling myself a faggot to offend the homophob...  white_supremacist\n",
       "1043  i 'm a proud faggot , and i should not be bann...  white_supremacist\n",
       "1044           well , i am happily a faggot and proud !  white_supremacist\n",
       "1047        happy pride month ! i love being a faggot !  white_supremacist\n",
       "...                                                 ...                ...\n",
       "2710  there have to be consequences for saying you w...  white_supremacist\n",
       "2742  why would you think it 's okay to call me a fa...  white_supremacist\n",
       "2745  why would you think it 's okay to call me a ni...  white_supremacist\n",
       "2754  why would you think it 's okay to call me a ra...  white_supremacist\n",
       "2761  if you 're telling immigrants to go fuck thems...  white_supremacist\n",
       "\n",
       "[199 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['predicted'] = preds.values\n",
    "data[data['predicted']=='white_supremacist'][['text', 'predicted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "205dbd0f-a00b-439b-a083-ac0d4717fa47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ws = data[data['predicted']=='white_supremacist']\n",
    "len(pred_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a33382ad-e048-4ce8-ade3-e28cf04a984f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610d7325e7b54f1c96742e887f23e0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make sure these are predicted white supremacist\n",
    "\n",
    "def preprocess(df):\n",
    "    return tokenizer(df[\"text\"], truncation=True)\n",
    "\n",
    "dataset = Dataset.from_pandas(pred_ws)\n",
    "tokenized = dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c9f47c2-0ed4-4731-8ff1-17327af71d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: functionality, focus_words, direction, label_gold, templ_id, focus_lemma, target_ident, ref_templ_id, test_case, case_id, case_templ, __index_level_0__, predicted, text, ref_case_id. If functionality, focus_words, direction, label_gold, templ_id, focus_lemma, target_ident, ref_templ_id, test_case, case_id, case_templ, __index_level_0__, predicted, text, ref_case_id are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 199\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "output = trainer.predict(tokenized)\n",
    "\n",
    "# Binary predictions\n",
    "preds = np.argmax(output.predictions, axis=-1)\n",
    "preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
