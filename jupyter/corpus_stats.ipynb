{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e4363a-cd61-4856-91f1-fb6b494d8270",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Check processed corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9848a8-3280-4b5c-a57e-579f25554f48",
   "metadata": {},
   "source": [
    "## Check short posts in white supremacist corpus to see if express the ideology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b4e67f-e5f1-47d2-980a-51895d3b0256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load white supremacist corpus\n",
    "import pandas as pd\n",
    "\n",
    "path = '../tmp/white_supremacist_train_corpus.pkl'\n",
    "data = pd.read_pickle(path)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f51c4f-a08b-4a92-8c06-e0d9a402fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View short posts across domains\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "for domain in data.domain.unique():\n",
    "    print(domain)\n",
    "    domain_data = data.query('domain==@domain')\n",
    "    short = domain_data[domain_data.text.str.split().str.len() <= 10]\n",
    "    display(short.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4817e2d-323d-495a-aebd-331fd510f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View distribution of post length overall\n",
    "import plotly.express as px\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "lengths = data.text.str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1b546-92c6-454f-8d77-01cfe1d30741",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['length'] = lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09b7cc7-7ded-408f-8030-23c9f0709d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "sampled = lengths.sample(int(1e6))\n",
    "sampled[sampled < 200].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e53b7-b48c-47ed-9e5b-68fd0cb79001",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.domain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b57275-8f58-4192-bd53-add433be25bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lengths across domains\n",
    "s = data[data.length < 100].sample(int(1e6))\n",
    "# s.hist(column='length')\n",
    "px.histogram(s, x='length', color='domain', barmode='overlay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78c222b-3ce0-409c-894b-c2be1291dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lengths across non-forum domains\n",
    "s = data.query('length < 100 and domain != \"forum\"')\n",
    "# s.hist(column='length')\n",
    "px.histogram(s, x='length', color='domain', barmode='overlay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa545273-9159-4b56-b7d3-c849baed2ad4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdf = lengths.value_counts().sort_index().cumsum()/len(lengths)\n",
    "cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce7f06-6377-4762-adcc-89bb507fca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(cdf[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa014d82-19f9-4669-af07-eb15d490f69c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cdfs = {domain: data[data.domain==domain]['length'].value_counts().sort_index().cumsum()/len(data) for domain in data.domain.unique()}\n",
    "# cdfs = pd.concat([pd.DataFrame(\n",
    "#     {'cumsum': data[data.domain==domain]['length'].value_counts().sort_index().cumsum()/len(data), 'domain': domain}) for domain in data.domain.unique()\n",
    "#                  ])\n",
    "cdfs = pd.concat([pd.DataFrame(\n",
    "    data[data.domain==domain]['length'].value_counts().sort_index().cumsum()/len(data[data.domain==domain])).assign(domain=domain).rename_axis('value').reset_index() for domain in data.domain.unique()\n",
    "                 ])\n",
    "cdfs.info()\n",
    "cdfs[cdfs.value <= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63d4842-2733-48b3-93e8-c4af1f9c32f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(cdfs[cdfs.value <= 100], x='value', y='length', color='domain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd7f49f-01d2-4f36-8880-06543647eca6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Corpus stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8253c5f8-f614-40a0-aa04-c608abad016e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3299122 entries, qian2018_0 to pruden2022_161\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Dtype              \n",
      "---  ------     -----              \n",
      " 0   text       object             \n",
      " 1   dataset    object             \n",
      " 2   source     object             \n",
      " 3   domain     object             \n",
      " 4   timestamp  datetime64[ns, UTC]\n",
      " 5   num_words  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(4)\n",
      "memory usage: 176.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import pandas as pd\n",
    "\n",
    "path = '../tmp/white_supremacist_train_corpus.pkl'\n",
    "# path = '../tmp/antiracist_train_corpus.pkl'\n",
    "# path = '../tmp/domain_test_corpus.pkl'\n",
    "data = pd.read_pickle(path)\n",
    "# path = '../data/corpora/white_supremacist_corpus.json'\n",
    "# data = pd.read_json(path, orient='table')\n",
    "# print(len(data))\n",
    "# data.columns\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd805227-7e8c-465a-a88b-e6a99294afaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_post_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chat</th>\n",
       "      <td>18739</td>\n",
       "      <td>425654</td>\n",
       "      <td>22.714873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forum</th>\n",
       "      <td>3171564</td>\n",
       "      <td>206524897</td>\n",
       "      <td>65.117682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long-form</th>\n",
       "      <td>38036</td>\n",
       "      <td>11420987</td>\n",
       "      <td>300.267825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <td>70783</td>\n",
       "      <td>1253683</td>\n",
       "      <td>17.711640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>3299122</td>\n",
       "      <td>219625221</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           post_count  word_count  avg_post_length\n",
       "chat            18739      425654        22.714873\n",
       "forum         3171564   206524897        65.117682\n",
       "long-form       38036    11420987       300.267825\n",
       "tweet           70783     1253683        17.711640\n",
       "total         3299122   219625221              NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Post and word counts total and per domain\n",
    "data['num_words'] = data.text.str.split().str.len()\n",
    "stats = data.groupby('domain').agg({'num_words': ['count', 'sum', 'mean']})\n",
    "stats.columns = ['post_count', 'word_count', 'avg_post_length']\n",
    "stats\n",
    "\n",
    "total = pd.DataFrame({'post_count': len(data), 'word_count': data.num_words.sum()}, index=['total'])\n",
    "total\n",
    "\n",
    "pd.concat([stats,total])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45beea0b-c7d2-4a9f-84ec-1e5821d8972b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "papasavva2020       1901408\n",
       "stormfront           706232\n",
       "jokubausaite2020     415921\n",
       "ironmarch            148003\n",
       "qian2018              66294\n",
       "calderon2021          25685\n",
       "patriotfront          18739\n",
       "pruden2022            12351\n",
       "elsherief2021          4489\n",
       "Name: dataset, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d76055-18e8-45ea-9069-e83121f11119",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.groupby(['domain', 'dataset'])['text'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442097a0-3529-4611-833b-6b36ee54ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = data.groupby(['domain', 'dataset'])['text'].count().reset_index()\n",
    "counts = data.groupby(['domain', 'dataset'])['text'].count()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd16aa60-7c0f-47cc-bde8-ed500cebe826",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['domain', 'dataset', 'source'])['text'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b37361-ff76-46c8-971c-9d31cbba8e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't figure out how to sort wihin domains\n",
    "# counts.sort_values(['domain', 'dataset'], ascending=False).groupby('domain').groups()\n",
    "# counts.sort_values(['domain', 'dataset'], ascending=False).groupby('domain')['text'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9ca2b1-5c86-49a8-a69b-1a1fa1721527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num of posts from each dataset (maybe should do log scale)\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "vc = data.dataset.value_counts()\n",
    "print(vc)\n",
    "vc.plot.bar(text=vc.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494713d-fa60-41ee-abcd-fbefa36eccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num of posts from each dataset (maybe should do log scale)\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "vc = data.dataset.value_counts()\n",
    "print(vc)\n",
    "vc.plot.bar(text=vc.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662bba68-3819-48c5-b2cc-1605cf757cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of words\n",
    "data['num_words'] = data.text.str.split().str.len()\n",
    "# data.head()\n",
    "\n",
    "word_count =  data.groupby('dataset')['num_words'].sum()\n",
    "display(word_count)\n",
    "word_count.sort_values(ascending=False).plot.bar().show()\n",
    "\n",
    "# Total posts and words\n",
    "print(f'{len(data)} posts')\n",
    "print(f'{word_count.sum()} words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed123a4b-900c-4685-b901-2239697c7990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# By domain\n",
    "dataset_info = pd.DataFrame([\n",
    "    {'dataset': 'qian2018', 'domain': 'tweet/short propaganda'},\n",
    "    {'dataset': 'elsherief2021', 'domain': 'tweet/short propaganda'},\n",
    "    {'dataset': 'degibert2019', 'domain': 'forum'},\n",
    "    {'dataset': 'patriotfront', 'domain': 'chat'},\n",
    "    {'dataset': 'alatawi2021', 'domain': 'tweet/short propaganda'},\n",
    "    {'dataset': 'adl_heatmap', 'domain': 'tweet/short propaganda'},\n",
    "    {'dataset': 'ironmarch', 'domain': 'forum'},\n",
    "    {'dataset': '4chan', 'domain': 'forum'},\n",
    "    {'dataset': 'stormfront', 'domain': 'forum'},\n",
    "    {'dataset': 'calderon2021', 'domain': 'long-form'},\n",
    "    {'dataset': 'pruden2022', 'domain': 'long-form'},\n",
    "]).set_index('dataset')\n",
    "dataset_info\n",
    "\n",
    "# data.join(dataset_info, on='dataset').domain.value_counts().plot.bar(\n",
    "#     title=\"Number of posts by domain\", \n",
    "#     labels=dict(index='domain', value='number of posts'),\n",
    "# )\n",
    "\n",
    "vc = data.join(dataset_info, on='dataset').domain.value_counts()\n",
    "fig = px.bar(vc, title=\"Number of posts by domain\", \n",
    "       labels=dict(index='domain', value='number of posts'),\n",
    "        text = [f'{val}<br>{val/vc.sum(): .1%}' for val in vc.values],\n",
    "    )\n",
    "fig.update_layout(showlegend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6049a2e3-769e-4b0b-ba99-4e4a4c2a38e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = data.join(dataset_info, on='dataset').groupby('domain')['num_words'].sum().sort_values(ascending=False)\n",
    "fig = px.bar(num_words,\n",
    "    title=\"Number of words by domain\", \n",
    "    labels=dict(index='domain', value='number of words'),\n",
    "    text = [f'{val}<br>{val/num_words.sum(): .1%}' for val in num_words.values],\n",
    "       # log_y=True\n",
    "    )\n",
    "fig.update_layout(showlegend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8cdc9-9d4d-4e8c-8777-1ef7443a0302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate date ranges\n",
    "print(len(data))\n",
    "print(data.timestamp.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6f3c9f-3524-4293-94c1-87e300d22cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = 'plotly'\n",
    "data.timestamp.sample(int(1e6)).hist()\n",
    "# data.timestamp.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b95289-3a7a-4883-a42d-1c53b74e03aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp(year=2000, month=1, day=1, tz='utc')\n",
    "data.query('timestamp > @start_date').timestamp.sample(int(1e5)).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791893aa-bb72-4ce7-9afe-23fcbd226a10",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bin or group by month\n",
    "import plotly.express as px\n",
    "# pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "start_date = pd.Timestamp(year=2000, month=1, day=1, tz='utc')\n",
    "merged =  data.join(dataset_info, on='dataset').query('timestamp > @start_date').sample(int(1e6))\n",
    "# merged.hist(column='timestamp', by='domain')\n",
    "# merged.hist(column=['timestamp'])\n",
    "px.histogram(merged, x='timestamp', color='domain', barmode=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac189ce-3d84-4060-b7c2-9ac453f30098",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bin or group by month\n",
    "px.histogram(merged, x='timestamp', color='domain', barmode='overlay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea3538-5676-4986-b092-9d3724fd8376",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.histogram(data.query('domain==\"forum\"').sample(int(1e5)), x='timestamp', color='dataset', barmode='overlay')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
