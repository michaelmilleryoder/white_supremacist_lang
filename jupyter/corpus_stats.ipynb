{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e4363a-cd61-4856-91f1-fb6b494d8270",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Check processed corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1829ee22-a828-4eeb-a86d-abbe80b07315",
   "metadata": {},
   "source": [
    "## Search for examples of non-hate speech white supremacist ideology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ca520e-0d69-407d-b92a-0f1b84f997e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 118842 entries, calderon2021_daily_stormer_0 to stormfront_99968\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count   Dtype              \n",
      "---  ------      --------------   -----              \n",
      " 0   text        118842 non-null  object             \n",
      " 1   word_count  118842 non-null  int64              \n",
      " 2   dataset     118842 non-null  object             \n",
      " 3   source      118842 non-null  object             \n",
      " 4   domain      118842 non-null  object             \n",
      " 5   timestamp   118810 non-null  datetime64[ns, UTC]\n",
      " 6   topic       118842 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load corresponding ws corpus to compare domain distribution\n",
    "import pandas as pd\n",
    "\n",
    "path = '../tmp/white_supremacist_train_6topic_corpus.pkl'\n",
    "ws_data = pd.read_pickle(path)\n",
    "ws_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd1b9df-0193-42e2-87c7-c1a265279185",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "ws_data.sample(100)[['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce445c6-333a-4152-927a-fdfdd6e6ff5b",
   "metadata": {},
   "source": [
    "## Anti-racist corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a985fd98-2041-4b29-8953-128ae4855924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as p\n",
    "path = '../tmp/antiracist_train_6topic_corpus.pkl'\n",
    "\n",
    "data = pd.read_pickle(path)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8386a1f-a5e2-46a2-a27f-767328b2dd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>forum</th>\n",
       "      <td>82349</td>\n",
       "      <td>0.937820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <td>3569</td>\n",
       "      <td>0.040645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long-form</th>\n",
       "      <td>1891</td>\n",
       "      <td>0.021535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           domain    domain\n",
       "forum       82349  0.937820\n",
       "tweet        3569  0.040645\n",
       "long-form    1891  0.021535"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([data.domain.value_counts(), data.domain.value_counts(normalize=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9799858-ae1f-46a2-b43c-b84ea824aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load corresponding ws corpus to compare domain distribution\n",
    "path = '../tmp/white_supremacist_train_6topic_corpus.pkl'\n",
    "ws_data = pd.read_pickle(path)\n",
    "ws_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98e29098-a792-4f01-9672-4a069de425fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>forum</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.841453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <td>9552</td>\n",
       "      <td>0.080376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long-form</th>\n",
       "      <td>7668</td>\n",
       "      <td>0.064523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chat</th>\n",
       "      <td>1622</td>\n",
       "      <td>0.013648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           domain    domain\n",
       "forum      100000  0.841453\n",
       "tweet        9552  0.080376\n",
       "long-form    7668  0.064523\n",
       "chat         1622  0.013648"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([ws_data.domain.value_counts(), ws_data.domain.value_counts(normalize=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97aaf978-8c27-434f-a95d-ba7a0ac284fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 159019 entries, twitter_match_0 to news_match_1882\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count   Dtype              \n",
      "---  ------      --------------   -----              \n",
      " 0   text        159019 non-null  object             \n",
      " 1   word_count  159019 non-null  int64              \n",
      " 2   dataset     159019 non-null  object             \n",
      " 3   source      159019 non-null  object             \n",
      " 4   domain      159019 non-null  object             \n",
      " 5   timestamp   156095 non-null  datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(4)\n",
      "memory usage: 8.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>forum</th>\n",
       "      <td>150832</td>\n",
       "      <td>0.948516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <td>3381</td>\n",
       "      <td>0.021262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chat</th>\n",
       "      <td>2924</td>\n",
       "      <td>0.018388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long-form</th>\n",
       "      <td>1882</td>\n",
       "      <td>0.011835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           domain    domain\n",
       "forum      150832  0.948516\n",
       "tweet        3381  0.021262\n",
       "chat         2924  0.018388\n",
       "long-form    1882  0.011835"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load corresponding neutral corpus to compare domain distribution\n",
    "path = '../tmp/neutral_train_6topic_corpus.pkl'\n",
    "neutral_data = pd.read_pickle(path)\n",
    "neutral_data.info()\n",
    "pd.concat([neutral_data.domain.value_counts(), neutral_data.domain.value_counts(normalize=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e34e075d-eaf9-4e2f-8b09-5506596edccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>dataset</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_29506</th>\n",
       "      <td>thank you i will get the book . i need to be better and erase things i learned and did n't even realize . but some things i say are very tiring apparently , so how do i distinguish what to say to someone who has experienced hardship and racism ? i 'm told they 're tired of supporting comments . we have normal conversations but i do n't know what to do because i just treat them as i would everybody else .</td>\n",
       "      <td>84</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2020-08-20 16:34:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_45566</th>\n",
       "      <td>did you do the art at franklin &amp; lyndale in minneapolis ?</td>\n",
       "      <td>12</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2020-06-24 00:56:10+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_62615</th>\n",
       "      <td>sushi</td>\n",
       "      <td>1</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2020-03-29 05:30:03+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_55201</th>\n",
       "      <td>ty . and yup . they ‚Äôre there to defend our rights . \\n\\n i ‚Äôm still trippin over the amish .</td>\n",
       "      <td>22</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2020-06-06 06:37:09+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_75574</th>\n",
       "      <td>do you think people should be violently attacked because they have a hateful agenda ?</td>\n",
       "      <td>15</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2016-02-29 15:10:01+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_195</th>\n",
       "      <td>blacks and whites what ?   socks ?   horses ?</td>\n",
       "      <td>11</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2022-09-17 03:06:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_87354</th>\n",
       "      <td>with all of this being said ; you do realize that with the \" ultimates storyline , \" they changed up the ethnicities of a number of the characters in the marvel universe . the biggest example of that is nick fury . \\n\\n anyway , the ultimate 's mandirin is of \" half - blood \" chinese ancestry , being the son of a descendant of genghis khan and an english noblewoman . so ben kingsley 's look actually fits the story .</td>\n",
       "      <td>84</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2012-10-24 01:03:20+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_53794</th>\n",
       "      <td>guess the argument 's over now</td>\n",
       "      <td>6</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2020-06-07 21:44:39+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_37832</th>\n",
       "      <td>do n't people realize saying ' black - on - black violence ' is racist and a distraction ? we do n't say ' white - on - white violence ' , even though 82 % of white people murdered was done by other white people . we do n't say , \" look at another white kid shooting up a school again . \" we do n't say , \" another whitey is raping again . \" we do n't say that because it would be * racist * . so , why is saying ' black - on - black violence ' an alright thing for these people to say ? oh that 's right , it 's just a distraction because they do n't think black lives matter .</td>\n",
       "      <td>132</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2020-07-13 03:16:08+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_88211</th>\n",
       "      <td>there is n't really an easy answer to this . the closest is ' sometimes ' . if you 're unsure , just do n't do it .</td>\n",
       "      <td>28</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2012-06-30 05:40:37+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_26951</th>\n",
       "      <td>and i have 0 confidence that it would change anything with police interactions ... like they straight up murdering people and do n‚Äôt seem to care \\n\\n maybe it ‚Äôs just my hot take as an outsider though üá® üá¶</td>\n",
       "      <td>40</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2020-08-30 16:57:38+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_54671</th>\n",
       "      <td>i ‚Äôm white and i ‚Äôve been protesting along side blm for years . this is ridiculous .</td>\n",
       "      <td>18</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2020-06-06 22:02:33+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_25581</th>\n",
       "      <td>this country is insane ...</td>\n",
       "      <td>5</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2020-09-07 19:33:09+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_42377</th>\n",
       "      <td>man this is deep .</td>\n",
       "      <td>5</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2020-07-01 18:57:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_24964</th>\n",
       "      <td>* * this is institutional and systemic racism baked into the us government in a nutshell :* * \\n\\n 1619 -   black people came to america in 1619 , 1 year before the pilgrims \\n\\n 1 . their stolen labor birthed the us economy and saved jamestown settlement \\n\\n 1630 - the city of boston is founded in the massachusetts bay colony \\n\\n 1718 - the city of new orleans is founded \\n\\n 1752 - the liberty bell is cracked when it is first rung \\n\\n 1770 - the boston massacre occurs , british police shoot up a crowd . \\n\\n 1773 - bostonian colonists protest the tea act with the boston tea party , where they riot and throw an entire beverage industry into the sea .   this is called \" independence \" for some reason \\n\\n 1775 - the revolutionary war begins with the declaration of independence , 156 years after the first slaves came to american shores . \\n\\n 1787 - 3/5ths compromise .   black people are counted for purposes of taxation and representation , but they only count as 3/5ths of a person . \\n\\n 1808 - usa abolishes the slave trade , but leaves existing american slaves in bondage . \\n\\n 1831 -   a slave named nat turner inspired a few dozen slaves from several virginia plantations to rise up .   turner led about seventy freedom fighters to kill about sixty white people over the course of two days .   nat turner and about 50 slaves were tried and executed . racist mobs rioted and lynched almost 200 more . they have been warning us how dangerous black people are since . \\n\\n 1850 - congress passed the fugitive slave act , which required all escaped slaves to be returned to their owners and american citizens to cooperate with the captures . \\n\\n 1857 - the us supreme court ruled : \\n\\n &gt; the constitution of the united states recognizes slaves as property , and pledges the federal government to protect it . and congress can not exercise any more authority over property of that description than it may constitutionally exercise over property of any other kind . ‚Äù \\n\\n nov 1860 - lincoln is elected , even tho 10 states did not include him on the ballot . \\n\\n dec 1860 - south carolina secedes from america with these words : \\n\\n &gt; by a vote of 169 - 0 , the south carolina legislature enacted an \" ordinance \" that \" the union now subsisting between south carolina and other states , under the name of ' the united states of america , ' is hereby dissolved . \\n\\n jan 1861 - mississippi , florida , alabama , georgia , louisiana and texas secede from america \\n\\n feb 1861 - the states combine to form the confederate states of america , an entirely different nation , and elect jefferson davis president \\n\\n apr 1861 - fort sumter , confederate forces fired shots at the fort and american troops surrendered .   this sparked the civil war , which lasted 4 years . \\n\\n apr 1861 - virginia secedes from america and joins the confederacy \\n\\n may/ june 1861 - arkansas , north carolina , and tennessee follow suit . \\n\\n 1862 - congress outlaws slavery \\n\\n 1863 - lincoln issues the emancipation proclamation \\n\\n 1864 - lincoln is re - elected to a second term \\n\\n april 9 , 1865 - general lee surrenders , the civil war ends , and the confederacy of 11 states ends \\n\\n lincoln is assassinated 5 days later . the kkk was formed a few months later in tennessee on christmas eve . \\n\\n 1870s - 1970s : there was a 10 year period after the civil war , where black people voted and were elected and were able to participate in the government ,   but within 10 years , the kkk kicked them out and instituted a system of anti - black laws that lasted 100 years until mlk was killed in 1968 . \\n\\n this system of laws lasted officially all the way to the 1970s .   and all those assholes are still in power . \\n\\n [ \\n\\n do not be afraid to copy this to other places on the internet</td>\n",
       "      <td>725</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2020-09-11 00:44:18+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_65861</th>\n",
       "      <td>lost him too late imo , good riddance</td>\n",
       "      <td>8</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2021-01-20 03:03:34+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_29244</th>\n",
       "      <td>i been looking , there 's almost 0 news online about this .</td>\n",
       "      <td>13</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2020-08-21 23:06:34+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_26414</th>\n",
       "      <td>they would n't call it reparations if she was white .</td>\n",
       "      <td>11</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2020-09-02 12:25:39+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_55013</th>\n",
       "      <td>what have they been doing ?</td>\n",
       "      <td>6</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2020-06-06 14:12:08+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit_antiracist_52429</th>\n",
       "      <td>we need the police though .</td>\n",
       "      <td>6</td>\n",
       "      <td>reddit_antiracist</td>\n",
       "      <td>reddit</td>\n",
       "      <td>forum</td>\n",
       "      <td>2020-06-10 00:21:29+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \\\n",
       "id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "reddit_antiracist_29506                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        thank you i will get the book . i need to be better and erase things i learned and did n't even realize . but some things i say are very tiring apparently , so how do i distinguish what to say to someone who has experienced hardship and racism ? i 'm told they 're tired of supporting comments . we have normal conversations but i do n't know what to do because i just treat them as i would everybody else .   \n",
       "reddit_antiracist_45566                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      did you do the art at franklin & lyndale in minneapolis ?   \n",
       "reddit_antiracist_62615                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          sushi   \n",
       "reddit_antiracist_55201                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ty . and yup . they ‚Äôre there to defend our rights . \\n\\n i ‚Äôm still trippin over the amish .   \n",
       "reddit_antiracist_75574                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          do you think people should be violently attacked because they have a hateful agenda ?   \n",
       "reddit_antiracist_195                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    blacks and whites what ?   socks ?   horses ?   \n",
       "reddit_antiracist_87354                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            with all of this being said ; you do realize that with the \" ultimates storyline , \" they changed up the ethnicities of a number of the characters in the marvel universe . the biggest example of that is nick fury . \\n\\n anyway , the ultimate 's mandirin is of \" half - blood \" chinese ancestry , being the son of a descendant of genghis khan and an english noblewoman . so ben kingsley 's look actually fits the story .   \n",
       "reddit_antiracist_53794                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 guess the argument 's over now   \n",
       "reddit_antiracist_37832                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             do n't people realize saying ' black - on - black violence ' is racist and a distraction ? we do n't say ' white - on - white violence ' , even though 82 % of white people murdered was done by other white people . we do n't say , \" look at another white kid shooting up a school again . \" we do n't say , \" another whitey is raping again . \" we do n't say that because it would be * racist * . so , why is saying ' black - on - black violence ' an alright thing for these people to say ? oh that 's right , it 's just a distraction because they do n't think black lives matter .   \n",
       "reddit_antiracist_88211                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            there is n't really an easy answer to this . the closest is ' sometimes ' . if you 're unsure , just do n't do it .   \n",
       "reddit_antiracist_26951                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  and i have 0 confidence that it would change anything with police interactions ... like they straight up murdering people and do n‚Äôt seem to care \\n\\n maybe it ‚Äôs just my hot take as an outsider though üá® üá¶   \n",
       "reddit_antiracist_54671                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           i ‚Äôm white and i ‚Äôve been protesting along side blm for years . this is ridiculous .   \n",
       "reddit_antiracist_25581                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     this country is insane ...   \n",
       "reddit_antiracist_42377                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             man this is deep .   \n",
       "reddit_antiracist_24964  * * this is institutional and systemic racism baked into the us government in a nutshell :* * \\n\\n 1619 -   black people came to america in 1619 , 1 year before the pilgrims \\n\\n 1 . their stolen labor birthed the us economy and saved jamestown settlement \\n\\n 1630 - the city of boston is founded in the massachusetts bay colony \\n\\n 1718 - the city of new orleans is founded \\n\\n 1752 - the liberty bell is cracked when it is first rung \\n\\n 1770 - the boston massacre occurs , british police shoot up a crowd . \\n\\n 1773 - bostonian colonists protest the tea act with the boston tea party , where they riot and throw an entire beverage industry into the sea .   this is called \" independence \" for some reason \\n\\n 1775 - the revolutionary war begins with the declaration of independence , 156 years after the first slaves came to american shores . \\n\\n 1787 - 3/5ths compromise .   black people are counted for purposes of taxation and representation , but they only count as 3/5ths of a person . \\n\\n 1808 - usa abolishes the slave trade , but leaves existing american slaves in bondage . \\n\\n 1831 -   a slave named nat turner inspired a few dozen slaves from several virginia plantations to rise up .   turner led about seventy freedom fighters to kill about sixty white people over the course of two days .   nat turner and about 50 slaves were tried and executed . racist mobs rioted and lynched almost 200 more . they have been warning us how dangerous black people are since . \\n\\n 1850 - congress passed the fugitive slave act , which required all escaped slaves to be returned to their owners and american citizens to cooperate with the captures . \\n\\n 1857 - the us supreme court ruled : \\n\\n > the constitution of the united states recognizes slaves as property , and pledges the federal government to protect it . and congress can not exercise any more authority over property of that description than it may constitutionally exercise over property of any other kind . ‚Äù \\n\\n nov 1860 - lincoln is elected , even tho 10 states did not include him on the ballot . \\n\\n dec 1860 - south carolina secedes from america with these words : \\n\\n > by a vote of 169 - 0 , the south carolina legislature enacted an \" ordinance \" that \" the union now subsisting between south carolina and other states , under the name of ' the united states of america , ' is hereby dissolved . \\n\\n jan 1861 - mississippi , florida , alabama , georgia , louisiana and texas secede from america \\n\\n feb 1861 - the states combine to form the confederate states of america , an entirely different nation , and elect jefferson davis president \\n\\n apr 1861 - fort sumter , confederate forces fired shots at the fort and american troops surrendered .   this sparked the civil war , which lasted 4 years . \\n\\n apr 1861 - virginia secedes from america and joins the confederacy \\n\\n may/ june 1861 - arkansas , north carolina , and tennessee follow suit . \\n\\n 1862 - congress outlaws slavery \\n\\n 1863 - lincoln issues the emancipation proclamation \\n\\n 1864 - lincoln is re - elected to a second term \\n\\n april 9 , 1865 - general lee surrenders , the civil war ends , and the confederacy of 11 states ends \\n\\n lincoln is assassinated 5 days later . the kkk was formed a few months later in tennessee on christmas eve . \\n\\n 1870s - 1970s : there was a 10 year period after the civil war , where black people voted and were elected and were able to participate in the government ,   but within 10 years , the kkk kicked them out and instituted a system of anti - black laws that lasted 100 years until mlk was killed in 1968 . \\n\\n this system of laws lasted officially all the way to the 1970s .   and all those assholes are still in power . \\n\\n [ \\n\\n do not be afraid to copy this to other places on the internet   \n",
       "reddit_antiracist_65861                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          lost him too late imo , good riddance   \n",
       "reddit_antiracist_29244                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    i been looking , there 's almost 0 news online about this .   \n",
       "reddit_antiracist_26414                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          they would n't call it reparations if she was white .   \n",
       "reddit_antiracist_55013                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    what have they been doing ?   \n",
       "reddit_antiracist_52429                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    we need the police though .   \n",
       "\n",
       "                         word_count            dataset  source domain  \\\n",
       "id                                                                      \n",
       "reddit_antiracist_29506          84  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_45566          12  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_62615           1  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_55201          22  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_75574          15  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_195            11  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_87354          84  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_53794           6  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_37832         132  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_88211          28  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_26951          40  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_54671          18  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_25581           5  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_42377           5  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_24964         725  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_65861           8  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_29244          13  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_26414          11  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_55013           6  reddit_antiracist  reddit  forum   \n",
       "reddit_antiracist_52429           6  reddit_antiracist  reddit  forum   \n",
       "\n",
       "                                        timestamp  \n",
       "id                                                 \n",
       "reddit_antiracist_29506 2020-08-20 16:34:57+00:00  \n",
       "reddit_antiracist_45566 2020-06-24 00:56:10+00:00  \n",
       "reddit_antiracist_62615 2020-03-29 05:30:03+00:00  \n",
       "reddit_antiracist_55201 2020-06-06 06:37:09+00:00  \n",
       "reddit_antiracist_75574 2016-02-29 15:10:01+00:00  \n",
       "reddit_antiracist_195   2022-09-17 03:06:00+00:00  \n",
       "reddit_antiracist_87354 2012-10-24 01:03:20+00:00  \n",
       "reddit_antiracist_53794 2020-06-07 21:44:39+00:00  \n",
       "reddit_antiracist_37832 2020-07-13 03:16:08+00:00  \n",
       "reddit_antiracist_88211 2012-06-30 05:40:37+00:00  \n",
       "reddit_antiracist_26951 2020-08-30 16:57:38+00:00  \n",
       "reddit_antiracist_54671 2020-06-06 22:02:33+00:00  \n",
       "reddit_antiracist_25581 2020-09-07 19:33:09+00:00  \n",
       "reddit_antiracist_42377 2020-07-01 18:57:29+00:00  \n",
       "reddit_antiracist_24964 2020-09-11 00:44:18+00:00  \n",
       "reddit_antiracist_65861 2021-01-20 03:03:34+00:00  \n",
       "reddit_antiracist_29244 2020-08-21 23:06:34+00:00  \n",
       "reddit_antiracist_26414 2020-09-02 12:25:39+00:00  \n",
       "reddit_antiracist_55013 2020-06-06 14:12:08+00:00  \n",
       "reddit_antiracist_52429 2020-06-10 00:21:29+00:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "data.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1254802a-c6e3-48de-91d7-4946f6eca1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>dataset</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_2043</th>\n",
       "      <td>that something is election rigging &amp; voter suppression . trump's ' election integrity commission ' is up to something ht</td>\n",
       "      <td>22</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2017-07-01 00:51:25+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_682</th>\n",
       "      <td>def : #holtzclawtrial keeps sarcastically referring to daniel as sinister . really emphasizing that daniel was only doing</td>\n",
       "      <td>20</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2015-12-07 22:12:24+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_1818</th>\n",
       "      <td>the jfrej community always stands with like she's always stood with our community . our letter :</td>\n",
       "      <td>19</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2017-04-29 02:41:42+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_383</th>\n",
       "      <td>we're bringing mom jeans back , y'all .</td>\n",
       "      <td>8</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2014-11-07 01:11:56+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_2908</th>\n",
       "      <td>#teamsistersong is in durham to take a stand . need to reschedule #queeringrj training with .</td>\n",
       "      <td>16</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2017-08-18 17:54:42+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_711</th>\n",
       "      <td>vanita gupta is setting the tone for president obama's division :</td>\n",
       "      <td>11</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2015-05-06 22:04:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_1784</th>\n",
       "      <td>despite being attorney general , jeff sessions is unaware that white extremist groups pose the greatest terror threat to law enforcement . he also could not name any of the many white supremacist groups that have carried out acts of terror . #sessionshearing</td>\n",
       "      <td>43</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2017-11-14 20:44:42+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_1001</th>\n",
       "      <td>states attorney charges officers in freddie grays death #baltimoreuprising</td>\n",
       "      <td>9</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2015-05-01 15:33:43+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_1911</th>\n",
       "      <td>these kids are fired up and they're not gonna let trump bully them anymore . their bonds are unbreakable &amp; they know #webelongtogether !</td>\n",
       "      <td>24</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2017-04-13 18:26:47+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_1071</th>\n",
       "      <td>. #fight4undocumd president loh , you didn't even ask for my consent in posting this tweet ! ! !</td>\n",
       "      <td>21</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2016-05-10 19:24:54+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_1347</th>\n",
       "      <td>. is right : the struggle for voting rights continues . + must help #restorethevra .</td>\n",
       "      <td>16</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2016-02-01 22:05:25+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_1374</th>\n",
       "      <td>looking forward to attending audre lorde's 82nd bday celebration tmrw &amp; learning more about the audre lorde proj</td>\n",
       "      <td>20</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2016-02-18 16:01:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_730</th>\n",
       "      <td>yes ! mt : thanks &amp; richard glatzer for telling caregiver stories in #stillalice . #dwdignity</td>\n",
       "      <td>16</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2015-02-25 20:54:18+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_2673</th>\n",
       "      <td>instead of raids , $ 3 billion would be much better spent investing in infrastructure and jobs . #fundfamiliesnotwalls #nobannowallnoraids</td>\n",
       "      <td>20</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2017-03-16 19:25:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_1742</th>\n",
       "      <td>we marched all over the country today , and we will keep organizing for all the days to come . #womensmarchonwashington #womens</td>\n",
       "      <td>24</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2017-01-22 01:45:36+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_1614</th>\n",
       "      <td>\" disparities do not happen in a vacuum ... result of disregard for health of black people . \" #blackmamasmatter #rj2016</td>\n",
       "      <td>21</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2016-03-22 16:16:51+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_2823</th>\n",
       "      <td>but instead of being treated as equal members of society upon their return , thousands of black veterans were accosted , attacked or lynched .</td>\n",
       "      <td>25</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2017-02-14 13:22:21+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_272</th>\n",
       "      <td>mt : we are here 2 tell to use their money 4 the people #risingvoices</td>\n",
       "      <td>15</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2014-04-28 13:10:36+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_1901</th>\n",
       "      <td>now : advocates are demanding stands up for #immigrants in miami-dade after expressing support for trumps depor</td>\n",
       "      <td>19</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2017-01-31 20:49:40+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter_antiracist_1205</th>\n",
       "      <td>us v . tx is about families - read the stories of those who need #scotus to #unfreezedapa at</td>\n",
       "      <td>21</td>\n",
       "      <td>twitter_antiracist</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2016-04-08 21:43:19+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                       text  \\\n",
       "id                                                                                                                                                                                                                                                                                            \n",
       "twitter_antiracist_2043                                                                                                                                            that something is election rigging & voter suppression . trump's ' election integrity commission ' is up to something ht   \n",
       "twitter_antiracist_682                                                                                                                                            def : #holtzclawtrial keeps sarcastically referring to daniel as sinister . really emphasizing that daniel was only doing   \n",
       "twitter_antiracist_1818                                                                                                                                                                    the jfrej community always stands with like she's always stood with our community . our letter :   \n",
       "twitter_antiracist_383                                                                                                                                                                                                                              we're bringing mom jeans back , y'all .   \n",
       "twitter_antiracist_2908                                                                                                                                                                       #teamsistersong is in durham to take a stand . need to reschedule #queeringrj training with .   \n",
       "twitter_antiracist_711                                                                                                                                                                                                    vanita gupta is setting the tone for president obama's division :   \n",
       "twitter_antiracist_1784  despite being attorney general , jeff sessions is unaware that white extremist groups pose the greatest terror threat to law enforcement . he also could not name any of the many white supremacist groups that have carried out acts of terror . #sessionshearing   \n",
       "twitter_antiracist_1001                                                                                                                                                                                          states attorney charges officers in freddie grays death #baltimoreuprising   \n",
       "twitter_antiracist_1911                                                                                                                            these kids are fired up and they're not gonna let trump bully them anymore . their bonds are unbreakable & they know #webelongtogether !   \n",
       "twitter_antiracist_1071                                                                                                                                                                    . #fight4undocumd president loh , you didn't even ask for my consent in posting this tweet ! ! !   \n",
       "twitter_antiracist_1347                                                                                                                                                                                . is right : the struggle for voting rights continues . + must help #restorethevra .   \n",
       "twitter_antiracist_1374                                                                                                                                                    looking forward to attending audre lorde's 82nd bday celebration tmrw & learning more about the audre lorde proj   \n",
       "twitter_antiracist_730                                                                                                                                                                        yes ! mt : thanks & richard glatzer for telling caregiver stories in #stillalice . #dwdignity   \n",
       "twitter_antiracist_2673                                                                                                                          instead of raids , $ 3 billion would be much better spent investing in infrastructure and jobs . #fundfamiliesnotwalls #nobannowallnoraids   \n",
       "twitter_antiracist_1742                                                                                                                                     we marched all over the country today , and we will keep organizing for all the days to come . #womensmarchonwashington #womens   \n",
       "twitter_antiracist_1614                                                                                                                                            \" disparities do not happen in a vacuum ... result of disregard for health of black people . \" #blackmamasmatter #rj2016   \n",
       "twitter_antiracist_2823                                                                                                                      but instead of being treated as equal members of society upon their return , thousands of black veterans were accosted , attacked or lynched .   \n",
       "twitter_antiracist_272                                                                                                                                                                                                mt : we are here 2 tell to use their money 4 the people #risingvoices   \n",
       "twitter_antiracist_1901                                                                                                                                                     now : advocates are demanding stands up for #immigrants in miami-dade after expressing support for trumps depor   \n",
       "twitter_antiracist_1205                                                                                                                                                                        us v . tx is about families - read the stories of those who need #scotus to #unfreezedapa at   \n",
       "\n",
       "                         word_count             dataset   source domain  \\\n",
       "id                                                                        \n",
       "twitter_antiracist_2043          22  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_682           20  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_1818          19  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_383            8  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_2908          16  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_711           11  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_1784          43  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_1001           9  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_1911          24  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_1071          21  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_1347          16  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_1374          20  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_730           16  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_2673          20  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_1742          24  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_1614          21  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_2823          25  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_272           15  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_1901          19  twitter_antiracist  twitter  tweet   \n",
       "twitter_antiracist_1205          21  twitter_antiracist  twitter  tweet   \n",
       "\n",
       "                                        timestamp  \n",
       "id                                                 \n",
       "twitter_antiracist_2043 2017-07-01 00:51:25+00:00  \n",
       "twitter_antiracist_682  2015-12-07 22:12:24+00:00  \n",
       "twitter_antiracist_1818 2017-04-29 02:41:42+00:00  \n",
       "twitter_antiracist_383  2014-11-07 01:11:56+00:00  \n",
       "twitter_antiracist_2908 2017-08-18 17:54:42+00:00  \n",
       "twitter_antiracist_711  2015-05-06 22:04:02+00:00  \n",
       "twitter_antiracist_1784 2017-11-14 20:44:42+00:00  \n",
       "twitter_antiracist_1001 2015-05-01 15:33:43+00:00  \n",
       "twitter_antiracist_1911 2017-04-13 18:26:47+00:00  \n",
       "twitter_antiracist_1071 2016-05-10 19:24:54+00:00  \n",
       "twitter_antiracist_1347 2016-02-01 22:05:25+00:00  \n",
       "twitter_antiracist_1374 2016-02-18 16:01:02+00:00  \n",
       "twitter_antiracist_730  2015-02-25 20:54:18+00:00  \n",
       "twitter_antiracist_2673 2017-03-16 19:25:02+00:00  \n",
       "twitter_antiracist_1742 2017-01-22 01:45:36+00:00  \n",
       "twitter_antiracist_1614 2016-03-22 16:16:51+00:00  \n",
       "twitter_antiracist_2823 2017-02-14 13:22:21+00:00  \n",
       "twitter_antiracist_272  2014-04-28 13:10:36+00:00  \n",
       "twitter_antiracist_1901 2017-01-31 20:49:40+00:00  \n",
       "twitter_antiracist_1205 2016-04-08 21:43:19+00:00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.dataset=='twitter_antiracist'].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960f54aa-e667-4134-aed8-bacee937f45a",
   "metadata": {},
   "source": [
    "## Check bias test (HateCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8256657b-7aec-490e-9222-4f4687f59d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2598 entries, hatecheck_sample_0 to hatecheck_sample_3727\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   text        2598 non-null   object\n",
      " 1   word_count  2598 non-null   int64 \n",
      " 2   dataset     2598 non-null   object\n",
      " 3   source      2598 non-null   object\n",
      " 4   domain      2598 non-null   object\n",
      " 5   label       2598 non-null   int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 142.1+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = '../tmp/bias_test_corpus.pkl'\n",
    "\n",
    "data = pd.read_pickle(path)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf8f8ac5-2ecf-463a-a200-cacb2c0a055f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hatecheck_sample'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dataset.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3007f65c-118f-47f5-99de-9efe0890270a",
   "metadata": {},
   "source": [
    "## Random sample to check quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05375a31-9661-401f-a416-9072840ef9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 106103 entries, calderon2021_daily_stormer_1002 to stormfront_99941\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count   Dtype              \n",
      "---  ------      --------------   -----              \n",
      " 0   text        106103 non-null  object             \n",
      " 1   word_count  106103 non-null  int64              \n",
      " 2   dataset     106103 non-null  object             \n",
      " 3   source      106103 non-null  object             \n",
      " 4   domain      106103 non-null  object             \n",
      " 5   timestamp   106092 non-null  datetime64[ns, UTC]\n",
      " 6   topic       106103 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load white supremacist training corpus\n",
    "import pandas as pd\n",
    "\n",
    "path = '../tmp/white_supremacist_train_corpus.pkl'\n",
    "ws_data = pd.read_pickle(path)\n",
    "ws_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe309d-daa1-42d9-b241-b4e1d6a08d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "ws_data.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b977a24-4851-4e67-888b-a4d250f6f9ce",
   "metadata": {},
   "source": [
    "## Check for the presence of Calderon2021 American Renaissance posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e11a9ef0-c3fc-47a9-9179-0f261b229461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3387954 entries, qian2018_0 to pruden2022_camus_the_great_replacement_book_161\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Dtype              \n",
      "---  ------      -----              \n",
      " 0   text        object             \n",
      " 1   word_count  int64              \n",
      " 2   dataset     object             \n",
      " 3   source      object             \n",
      " 4   domain      object             \n",
      " 5   timestamp   datetime64[ns, UTC]\n",
      " 6   num_words   int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 206.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load white supremacist corpus\n",
    "import pandas as pd\n",
    "\n",
    "path = '../tmp/white_supremacist_fulltext_train_corpus.pkl'\n",
    "ws_data = pd.read_pickle(path)\n",
    "ws_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f01faa42-34d2-4a10-92e3-53cf7e25a675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['twitter', 'discord', 'ironmarch', 'stormfront', '4chan',\n",
       "       'daily_stormer', 'breivik_manifesto',\n",
       "       'powell_rivers_of_blood_speech', 'raspail_camp_of_the_saints_book',\n",
       "       'lane_white_genocide_manifesto',\n",
       "       'camus_the_great_replacement_book'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_data.source.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8f774b-0e30-4841-91e8-1a0386bb2da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_data[ws_data.index.str.startswith('calderon')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5238f4f7-5ef6-4f61-b63c-bf97d956cc49",
   "metadata": {},
   "source": [
    "## Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a66648b-7088-4e66-9c6c-6c3fec5a3a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3264772 entries, qian2018_0 to pruden2022_161\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Dtype              \n",
      "---  ------      -----              \n",
      " 0   text        object             \n",
      " 1   word_count  int64              \n",
      " 2   dataset     object             \n",
      " 3   source      object             \n",
      " 4   domain      object             \n",
      " 5   timestamp   datetime64[ns, UTC]\n",
      " 6   num_words   int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 199.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load white supremacist corpus\n",
    "import pandas as pd\n",
    "\n",
    "# path = '../tmp/white_supremacist_train_corpus.pkl'\n",
    "path = '../tmp/white_supremacist_fulltext_train_corpus.pkl'\n",
    "ws_data = pd.read_pickle(path)\n",
    "ws_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87804af4-d7a7-49b0-b48f-68ba5eab81e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(ws_data.text.duplicated(keep='first').sum())\n",
    "print(ws_data.index.duplicated(keep='first').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bae8f9-1318-4791-9a56-87fec572c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = ws_data[ws_data.index.duplicated(keep=False)].sort_index()\n",
    "dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "779b0768-4849-4856-ab68-694e27f822a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patriotfront    5072\n",
       "pruden2022      1933\n",
       "Name: dataset, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dups.dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c5ceae-136b-4f0c-bf51-13a172675e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_data[ws_data.index.str.startswith('calderon')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "063064e0-b3f9-4c97-8c26-ca68f2a24320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>dataset</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, word_count, dataset, source, domain, timestamp, num_words]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_data[ws_data.index.str.startswith('calderon')].query('source==\"american_renaissance\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "529d9e56-450b-4464-911d-e1f9fd9f6f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['daily_stormer'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_data[ws_data.dataset=='calderon2021'].source.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a902ec-ba76-4616-916b-1073d081beeb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "print(ws_data.duplicated(subset=['text', 'dataset'], keep='first').sum())\n",
    "dups = ws_data[ws_data.duplicated(subset=['text', 'dataset'], keep=False)].sort_values('text')\n",
    "dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42eae7fd-2e57-4f8c-953c-3cbd95f8c088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calderon2021    472\n",
       "Name: dataset, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dups.dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5d1443-c3db-4a09-a364-893437b43bd2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dups = ws_data[ws_data.duplicated(['text'], keep=False)].sort_values('text')\n",
    "dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0079d287-323d-414a-8fc6-85fe30759745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "elsherief2021    1454\n",
       "qian2018         1454\n",
       "calderon2021      472\n",
       "Name: dataset, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dups.dataset.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62491ae-6b8f-4837-83d2-525d39c54fa1",
   "metadata": {},
   "source": [
    "## Check for long numbers (IDs) in Patriot Front chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b3920ba-d1b1-43bc-a904-636bf3637638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>dataset</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, word_count, dataset, source, domain, timestamp, num_words]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patriotfront = ws_data[ws_data.dataset=='patriotfront']\n",
    "patriotfront[patriotfront.text.str.contains('172809042299715584')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd21cf-cebc-4c7f-a20b-6a77e66a9710",
   "metadata": {},
   "source": [
    "## Check for Twitter errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64feacbd-f773-4c8d-ba4d-9fc7c60256ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>dataset</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, word_count, dataset, source, domain, timestamp, num_words]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_data[ws_data.text.str.contains(\"account is temporarily unavailable because it violates\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9848a8-3280-4b5c-a57e-579f25554f48",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check short posts in white supremacist corpus to see if express the ideology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b4e67f-e5f1-47d2-980a-51895d3b0256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4370588 entries, qian2018_0 to rieger2021_white_supremacist_4447\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Dtype              \n",
      "---  ------      -----              \n",
      " 0   text        object             \n",
      " 1   word_count  int64              \n",
      " 2   dataset     object             \n",
      " 3   source      object             \n",
      " 4   domain      object             \n",
      " 5   timestamp   datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(4)\n",
      "memory usage: 233.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load white supremacist corpus\n",
    "import pandas as pd\n",
    "\n",
    "# path = '../tmp/white_supremacist_train_corpus.pkl'\n",
    "path = '../tmp/white_supremacist_corpus.pkl'\n",
    "ws_data = pd.read_pickle(path)\n",
    "ws_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9c7cbc4-79ff-4120-9638-9ecf753ede3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "papasavva2020                    2686268\n",
       "stormfront                        751982\n",
       "jokubausaite2020                  578652\n",
       "ironmarch                         179468\n",
       "qian2018                           84696\n",
       "patriotfront                       39578\n",
       "calderon2021                       26009\n",
       "pruden2022                         17007\n",
       "elsherief2021                       3480\n",
       "adl_heatmap                         1819\n",
       "alatawi2021_white_supremacist       1098\n",
       "rieger2021_white_supremacist         361\n",
       "siegel2021_white_supremacist         170\n",
       "Name: dataset, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_data.dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "945c69fb-0746-416a-996b-955c39858c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forum        4196370\n",
       "tweet          88176\n",
       "long-form      43016\n",
       "chat           39578\n",
       "Name: domain, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_data[~ws_data.dataset.isin(['alatawi2021_white_supremacist', 'rieger2021_white_supremacist',\n",
    "                               'siegel2021_white_supremacist', 'adl_heatmap'])].domain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f51c4f-a08b-4a92-8c06-e0d9a402fedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>dataset</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qian2018_3355</th>\n",
       "      <td>they contributed also to women rights &amp; fashion</td>\n",
       "      <td>10</td>\n",
       "      <td>qian2018</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2014-07-09 20:44:24+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qian2018_85877</th>\n",
       "      <td>i just uploaded lost gospel of peter to #vimeo :</td>\n",
       "      <td>10</td>\n",
       "      <td>qian2018</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2017-09-11 11:55:42+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qian2018_28530</th>\n",
       "      <td>ok bj but it will cost</td>\n",
       "      <td>6</td>\n",
       "      <td>qian2018</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2015-08-15 08:21:45+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qian2018_5055</th>\n",
       "      <td>\" rivers of blood will flow \" # inhuman inbreeding</td>\n",
       "      <td>10</td>\n",
       "      <td>qian2018</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2014-09-13 21:33:05+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qian2018_28567</th>\n",
       "      <td>killa white skin head</td>\n",
       "      <td>4</td>\n",
       "      <td>qian2018</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2016-10-03 06:03:14+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qian2018_76668</th>\n",
       "      <td>misgendering gets teacher booted from school #tcot</td>\n",
       "      <td>7</td>\n",
       "      <td>qian2018</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2017-11-15 02:46:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qian2018_27579</th>\n",
       "      <td>white power fuck police utrecht en this white marocan trash</td>\n",
       "      <td>10</td>\n",
       "      <td>qian2018</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2016-03-03 06:37:56+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qian2018_65572</th>\n",
       "      <td>in short , multiculturalism destroys culture itself</td>\n",
       "      <td>7</td>\n",
       "      <td>qian2018</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2017-10-16 01:15:20+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qian2018_71855</th>\n",
       "      <td>santa monica synagogue vandalized with feces during hanukkah #tcot</td>\n",
       "      <td>9</td>\n",
       "      <td>qian2018</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2016-12-28 04:27:50+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qian2018_52479</th>\n",
       "      <td>crazy crazy</td>\n",
       "      <td>2</td>\n",
       "      <td>qian2018</td>\n",
       "      <td>twitter</td>\n",
       "      <td>tweet</td>\n",
       "      <td>2015-02-02 02:33:52+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              text  \\\n",
       "id                                                                                   \n",
       "qian2018_3355                      they contributed also to women rights & fashion   \n",
       "qian2018_85877                    i just uploaded lost gospel of peter to #vimeo :   \n",
       "qian2018_28530                                              ok bj but it will cost   \n",
       "qian2018_5055                   \" rivers of blood will flow \" # inhuman inbreeding   \n",
       "qian2018_28567                                               killa white skin head   \n",
       "qian2018_76668                  misgendering gets teacher booted from school #tcot   \n",
       "qian2018_27579         white power fuck police utrecht en this white marocan trash   \n",
       "qian2018_65572                 in short , multiculturalism destroys culture itself   \n",
       "qian2018_71855  santa monica synagogue vandalized with feces during hanukkah #tcot   \n",
       "qian2018_52479                                                         crazy crazy   \n",
       "\n",
       "                word_count   dataset   source domain                 timestamp  \n",
       "id                                                                              \n",
       "qian2018_3355           10  qian2018  twitter  tweet 2014-07-09 20:44:24+00:00  \n",
       "qian2018_85877          10  qian2018  twitter  tweet 2017-09-11 11:55:42+00:00  \n",
       "qian2018_28530           6  qian2018  twitter  tweet 2015-08-15 08:21:45+00:00  \n",
       "qian2018_5055           10  qian2018  twitter  tweet 2014-09-13 21:33:05+00:00  \n",
       "qian2018_28567           4  qian2018  twitter  tweet 2016-10-03 06:03:14+00:00  \n",
       "qian2018_76668           7  qian2018  twitter  tweet 2017-11-15 02:46:00+00:00  \n",
       "qian2018_27579          10  qian2018  twitter  tweet 2016-03-03 06:37:56+00:00  \n",
       "qian2018_65572           7  qian2018  twitter  tweet 2017-10-16 01:15:20+00:00  \n",
       "qian2018_71855           9  qian2018  twitter  tweet 2016-12-28 04:27:50+00:00  \n",
       "qian2018_52479           2  qian2018  twitter  tweet 2015-02-02 02:33:52+00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>dataset</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>patriotfront_43271</th>\n",
       "      <td>true enough .</td>\n",
       "      <td>3</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2018-03-02 17:28:09.205000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_16949</th>\n",
       "      <td>lol the bowl patrol . i like</td>\n",
       "      <td>7</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-07-24 23:41:05.141000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_18749</th>\n",
       "      <td>state</td>\n",
       "      <td>1</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-06-26 00:50:40.482000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_15988</th>\n",
       "      <td>+</td>\n",
       "      <td>1</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-08-11 06:53:01.924000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_570</th>\n",
       "      <td>chiggers and niggers .</td>\n",
       "      <td>4</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-07-26 07:20:58.536000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_24651</th>\n",
       "      <td>but dont speak for the organization itself</td>\n",
       "      <td>7</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-06-21 02:40:03.591000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_36354</th>\n",
       "      <td>reddit and twitter are cracking down hard today</td>\n",
       "      <td>8</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-10-25 21:14:27.228000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_10588</th>\n",
       "      <td>ban albert</td>\n",
       "      <td>2</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-06-20 23:32:37.614000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_20911</th>\n",
       "      <td>well , that one's in pristine condition and probably certified</td>\n",
       "      <td>10</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-07-23 02:41:49.594000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_33041</th>\n",
       "      <td>are heimbach memes the newest thing ?</td>\n",
       "      <td>7</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2018-02-11 05:41:55.506000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              text  \\\n",
       "id                                                                                   \n",
       "patriotfront_43271                                                   true enough .   \n",
       "patriotfront_16949                                    lol the bowl patrol . i like   \n",
       "patriotfront_18749                                                           state   \n",
       "patriotfront_15988                                                               +   \n",
       "patriotfront_570                                            chiggers and niggers .   \n",
       "patriotfront_24651                      but dont speak for the organization itself   \n",
       "patriotfront_36354                 reddit and twitter are cracking down hard today   \n",
       "patriotfront_10588                                                      ban albert   \n",
       "patriotfront_20911  well , that one's in pristine condition and probably certified   \n",
       "patriotfront_33041                           are heimbach memes the newest thing ?   \n",
       "\n",
       "                    word_count       dataset   source domain  \\\n",
       "id                                                             \n",
       "patriotfront_43271           3  patriotfront  discord   chat   \n",
       "patriotfront_16949           7  patriotfront  discord   chat   \n",
       "patriotfront_18749           1  patriotfront  discord   chat   \n",
       "patriotfront_15988           1  patriotfront  discord   chat   \n",
       "patriotfront_570             4  patriotfront  discord   chat   \n",
       "patriotfront_24651           7  patriotfront  discord   chat   \n",
       "patriotfront_36354           8  patriotfront  discord   chat   \n",
       "patriotfront_10588           2  patriotfront  discord   chat   \n",
       "patriotfront_20911          10  patriotfront  discord   chat   \n",
       "patriotfront_33041           7  patriotfront  discord   chat   \n",
       "\n",
       "                                          timestamp  \n",
       "id                                                   \n",
       "patriotfront_43271 2018-03-02 17:28:09.205000+00:00  \n",
       "patriotfront_16949 2017-07-24 23:41:05.141000+00:00  \n",
       "patriotfront_18749 2017-06-26 00:50:40.482000+00:00  \n",
       "patriotfront_15988 2017-08-11 06:53:01.924000+00:00  \n",
       "patriotfront_570   2017-07-26 07:20:58.536000+00:00  \n",
       "patriotfront_24651 2017-06-21 02:40:03.591000+00:00  \n",
       "patriotfront_36354 2017-10-25 21:14:27.228000+00:00  \n",
       "patriotfront_10588 2017-06-20 23:32:37.614000+00:00  \n",
       "patriotfront_20911 2017-07-23 02:41:49.594000+00:00  \n",
       "patriotfront_33041 2018-02-11 05:41:55.506000+00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>dataset</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>papasavva2020_287834</th>\n",
       "      <td>most effective post itt tb - h f - am</td>\n",
       "      <td>11</td>\n",
       "      <td>papasavva2020</td>\n",
       "      <td>4chan</td>\n",
       "      <td>forum</td>\n",
       "      <td>2017-07-06 03:54:13+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>papasavva2020_1523045</th>\n",
       "      <td>rabbi promoting christianity does not compute</td>\n",
       "      <td>7</td>\n",
       "      <td>papasavva2020</td>\n",
       "      <td>4chan</td>\n",
       "      <td>forum</td>\n",
       "      <td>2018-02-03 17:30:25+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>papasavva2020_742529</th>\n",
       "      <td>very good advice</td>\n",
       "      <td>4</td>\n",
       "      <td>papasavva2020</td>\n",
       "      <td>4chan</td>\n",
       "      <td>forum</td>\n",
       "      <td>2017-08-29 06:54:58+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>papasavva2020_2214593</th>\n",
       "      <td>poor alex , still feel bad for him .</td>\n",
       "      <td>10</td>\n",
       "      <td>papasavva2020</td>\n",
       "      <td>4chan</td>\n",
       "      <td>forum</td>\n",
       "      <td>2018-09-16 00:48:52+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>papasavva2020_3043282</th>\n",
       "      <td>they 're too busy diddling children .</td>\n",
       "      <td>8</td>\n",
       "      <td>papasavva2020</td>\n",
       "      <td>4chan</td>\n",
       "      <td>forum</td>\n",
       "      <td>2019-08-15 11:02:15+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jokubausaite2020_175303</th>\n",
       "      <td>that was scandalous shame on the roth bitch</td>\n",
       "      <td>9</td>\n",
       "      <td>jokubausaite2020</td>\n",
       "      <td>4chan</td>\n",
       "      <td>forum</td>\n",
       "      <td>2018-06-09 17:46:10+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jokubausaite2020_102683</th>\n",
       "      <td>what the fuck is sonstige ?</td>\n",
       "      <td>7</td>\n",
       "      <td>jokubausaite2020</td>\n",
       "      <td>4chan</td>\n",
       "      <td>forum</td>\n",
       "      <td>2018-02-12 20:32:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jokubausaite2020_460771</th>\n",
       "      <td>judaism is much more than just a race .</td>\n",
       "      <td>10</td>\n",
       "      <td>jokubausaite2020</td>\n",
       "      <td>4chan</td>\n",
       "      <td>forum</td>\n",
       "      <td>2017-03-23 18:44:19+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jokubausaite2020_52616</th>\n",
       "      <td>1 minute till reich it 's fucking happening</td>\n",
       "      <td>8</td>\n",
       "      <td>jokubausaite2020</td>\n",
       "      <td>4chan</td>\n",
       "      <td>forum</td>\n",
       "      <td>2017-09-24 11:59:16+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>papasavva2020_2281976</th>\n",
       "      <td>texas will be 50/50 by 2020</td>\n",
       "      <td>7</td>\n",
       "      <td>papasavva2020</td>\n",
       "      <td>4chan</td>\n",
       "      <td>forum</td>\n",
       "      <td>2018-10-12 20:12:59+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    text  \\\n",
       "id                                                                         \n",
       "papasavva2020_287834               most effective post itt tb - h f - am   \n",
       "papasavva2020_1523045      rabbi promoting christianity does not compute   \n",
       "papasavva2020_742529                                    very good advice   \n",
       "papasavva2020_2214593               poor alex , still feel bad for him .   \n",
       "papasavva2020_3043282              they 're too busy diddling children .   \n",
       "jokubausaite2020_175303      that was scandalous shame on the roth bitch   \n",
       "jokubausaite2020_102683                      what the fuck is sonstige ?   \n",
       "jokubausaite2020_460771          judaism is much more than just a race .   \n",
       "jokubausaite2020_52616       1 minute till reich it 's fucking happening   \n",
       "papasavva2020_2281976                        texas will be 50/50 by 2020   \n",
       "\n",
       "                         word_count           dataset source domain  \\\n",
       "id                                                                    \n",
       "papasavva2020_287834             11     papasavva2020  4chan  forum   \n",
       "papasavva2020_1523045             7     papasavva2020  4chan  forum   \n",
       "papasavva2020_742529              4     papasavva2020  4chan  forum   \n",
       "papasavva2020_2214593            10     papasavva2020  4chan  forum   \n",
       "papasavva2020_3043282             8     papasavva2020  4chan  forum   \n",
       "jokubausaite2020_175303           9  jokubausaite2020  4chan  forum   \n",
       "jokubausaite2020_102683           7  jokubausaite2020  4chan  forum   \n",
       "jokubausaite2020_460771          10  jokubausaite2020  4chan  forum   \n",
       "jokubausaite2020_52616            8  jokubausaite2020  4chan  forum   \n",
       "papasavva2020_2281976             7     papasavva2020  4chan  forum   \n",
       "\n",
       "                                        timestamp  \n",
       "id                                                 \n",
       "papasavva2020_287834    2017-07-06 03:54:13+00:00  \n",
       "papasavva2020_1523045   2018-02-03 17:30:25+00:00  \n",
       "papasavva2020_742529    2017-08-29 06:54:58+00:00  \n",
       "papasavva2020_2214593   2018-09-16 00:48:52+00:00  \n",
       "papasavva2020_3043282   2019-08-15 11:02:15+00:00  \n",
       "jokubausaite2020_175303 2018-06-09 17:46:10+00:00  \n",
       "jokubausaite2020_102683 2018-02-12 20:32:29+00:00  \n",
       "jokubausaite2020_460771 2017-03-23 18:44:19+00:00  \n",
       "jokubausaite2020_52616  2017-09-24 11:59:16+00:00  \n",
       "papasavva2020_2281976   2018-10-12 20:12:59+00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long-form\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>dataset</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pruden2022_breivik_manifesto_15856</th>\n",
       "      <td>¬• vehicle/vehicle repair officer</td>\n",
       "      <td>4</td>\n",
       "      <td>pruden2022</td>\n",
       "      <td>breivik_manifesto</td>\n",
       "      <td>long-form</td>\n",
       "      <td>2011-01-01 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pruden2022_breivik_manifesto_1701</th>\n",
       "      <td>the abbasid era ( 750-1258 )</td>\n",
       "      <td>6</td>\n",
       "      <td>pruden2022</td>\n",
       "      <td>breivik_manifesto</td>\n",
       "      <td>long-form</td>\n",
       "      <td>2011-01-01 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pruden2022_raspail_camp_of_the_saints_book_466</th>\n",
       "      <td>ten thousand kilometers √©</td>\n",
       "      <td>4</td>\n",
       "      <td>pruden2022</td>\n",
       "      <td>raspail_camp_of_the_saints_book</td>\n",
       "      <td>long-form</td>\n",
       "      <td>1973-01-01 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pruden2022_breivik_manifesto_17605</th>\n",
       "      <td>¬• 2,5kg of aspirin powder</td>\n",
       "      <td>5</td>\n",
       "      <td>pruden2022</td>\n",
       "      <td>breivik_manifesto</td>\n",
       "      <td>long-form</td>\n",
       "      <td>2011-01-01 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pruden2022_breivik_manifesto_7362</th>\n",
       "      <td>vilfredo pareto</td>\n",
       "      <td>2</td>\n",
       "      <td>pruden2022</td>\n",
       "      <td>breivik_manifesto</td>\n",
       "      <td>long-form</td>\n",
       "      <td>2011-01-01 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pruden2022_breivik_manifesto_16130</th>\n",
       "      <td>access to cobalt , copper and diamonds .</td>\n",
       "      <td>8</td>\n",
       "      <td>pruden2022</td>\n",
       "      <td>breivik_manifesto</td>\n",
       "      <td>long-form</td>\n",
       "      <td>2011-01-01 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pruden2022_breivik_manifesto_5331</th>\n",
       "      <td>othmaniyah</td>\n",
       "      <td>1</td>\n",
       "      <td>pruden2022</td>\n",
       "      <td>breivik_manifesto</td>\n",
       "      <td>long-form</td>\n",
       "      <td>2011-01-01 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pruden2022_breivik_manifesto_10275</th>\n",
       "      <td>5 . hide a knife behind a smile</td>\n",
       "      <td>8</td>\n",
       "      <td>pruden2022</td>\n",
       "      <td>breivik_manifesto</td>\n",
       "      <td>long-form</td>\n",
       "      <td>2011-01-01 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pruden2022_breivik_manifesto_15232</th>\n",
       "      <td>¬• supports the deportation of all muslims from europe</td>\n",
       "      <td>9</td>\n",
       "      <td>pruden2022</td>\n",
       "      <td>breivik_manifesto</td>\n",
       "      <td>long-form</td>\n",
       "      <td>2011-01-01 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pruden2022_breivik_manifesto_8416</th>\n",
       "      <td>`` social parasitism ''</td>\n",
       "      <td>4</td>\n",
       "      <td>pruden2022</td>\n",
       "      <td>breivik_manifesto</td>\n",
       "      <td>long-form</td>\n",
       "      <td>2011-01-01 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 text  \\\n",
       "id                                                                                                      \n",
       "pruden2022_breivik_manifesto_15856                                   ¬• vehicle/vehicle repair officer   \n",
       "pruden2022_breivik_manifesto_1701                                        the abbasid era ( 750-1258 )   \n",
       "pruden2022_raspail_camp_of_the_saints_book_466                              ten thousand kilometers √©   \n",
       "pruden2022_breivik_manifesto_17605                                          ¬• 2,5kg of aspirin powder   \n",
       "pruden2022_breivik_manifesto_7362                                                     vilfredo pareto   \n",
       "pruden2022_breivik_manifesto_16130                           access to cobalt , copper and diamonds .   \n",
       "pruden2022_breivik_manifesto_5331                                                          othmaniyah   \n",
       "pruden2022_breivik_manifesto_10275                                    5 . hide a knife behind a smile   \n",
       "pruden2022_breivik_manifesto_15232              ¬• supports the deportation of all muslims from europe   \n",
       "pruden2022_breivik_manifesto_8416                                             `` social parasitism ''   \n",
       "\n",
       "                                                word_count     dataset  \\\n",
       "id                                                                       \n",
       "pruden2022_breivik_manifesto_15856                       4  pruden2022   \n",
       "pruden2022_breivik_manifesto_1701                        6  pruden2022   \n",
       "pruden2022_raspail_camp_of_the_saints_book_466           4  pruden2022   \n",
       "pruden2022_breivik_manifesto_17605                       5  pruden2022   \n",
       "pruden2022_breivik_manifesto_7362                        2  pruden2022   \n",
       "pruden2022_breivik_manifesto_16130                       8  pruden2022   \n",
       "pruden2022_breivik_manifesto_5331                        1  pruden2022   \n",
       "pruden2022_breivik_manifesto_10275                       8  pruden2022   \n",
       "pruden2022_breivik_manifesto_15232                       9  pruden2022   \n",
       "pruden2022_breivik_manifesto_8416                        4  pruden2022   \n",
       "\n",
       "                                                                         source  \\\n",
       "id                                                                                \n",
       "pruden2022_breivik_manifesto_15856                            breivik_manifesto   \n",
       "pruden2022_breivik_manifesto_1701                             breivik_manifesto   \n",
       "pruden2022_raspail_camp_of_the_saints_book_466  raspail_camp_of_the_saints_book   \n",
       "pruden2022_breivik_manifesto_17605                            breivik_manifesto   \n",
       "pruden2022_breivik_manifesto_7362                             breivik_manifesto   \n",
       "pruden2022_breivik_manifesto_16130                            breivik_manifesto   \n",
       "pruden2022_breivik_manifesto_5331                             breivik_manifesto   \n",
       "pruden2022_breivik_manifesto_10275                            breivik_manifesto   \n",
       "pruden2022_breivik_manifesto_15232                            breivik_manifesto   \n",
       "pruden2022_breivik_manifesto_8416                             breivik_manifesto   \n",
       "\n",
       "                                                   domain  \\\n",
       "id                                                          \n",
       "pruden2022_breivik_manifesto_15856              long-form   \n",
       "pruden2022_breivik_manifesto_1701               long-form   \n",
       "pruden2022_raspail_camp_of_the_saints_book_466  long-form   \n",
       "pruden2022_breivik_manifesto_17605              long-form   \n",
       "pruden2022_breivik_manifesto_7362               long-form   \n",
       "pruden2022_breivik_manifesto_16130              long-form   \n",
       "pruden2022_breivik_manifesto_5331               long-form   \n",
       "pruden2022_breivik_manifesto_10275              long-form   \n",
       "pruden2022_breivik_manifesto_15232              long-form   \n",
       "pruden2022_breivik_manifesto_8416               long-form   \n",
       "\n",
       "                                                               timestamp  \n",
       "id                                                                        \n",
       "pruden2022_breivik_manifesto_15856             2011-01-01 00:00:00+00:00  \n",
       "pruden2022_breivik_manifesto_1701              2011-01-01 00:00:00+00:00  \n",
       "pruden2022_raspail_camp_of_the_saints_book_466 1973-01-01 00:00:00+00:00  \n",
       "pruden2022_breivik_manifesto_17605             2011-01-01 00:00:00+00:00  \n",
       "pruden2022_breivik_manifesto_7362              2011-01-01 00:00:00+00:00  \n",
       "pruden2022_breivik_manifesto_16130             2011-01-01 00:00:00+00:00  \n",
       "pruden2022_breivik_manifesto_5331              2011-01-01 00:00:00+00:00  \n",
       "pruden2022_breivik_manifesto_10275             2011-01-01 00:00:00+00:00  \n",
       "pruden2022_breivik_manifesto_15232             2011-01-01 00:00:00+00:00  \n",
       "pruden2022_breivik_manifesto_8416              2011-01-01 00:00:00+00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offline_propaganda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>dataset</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adl_heatmap_174</th>\n",
       "      <td>`` cleansing ''</td>\n",
       "      <td>3</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>offline_propaganda</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adl_heatmap_1205</th>\n",
       "      <td>`` anti antifa ''</td>\n",
       "      <td>4</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>offline_propaganda</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adl_heatmap_881</th>\n",
       "      <td>`` our revolution is tradition ''</td>\n",
       "      <td>6</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>offline_propaganda</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adl_heatmap_168</th>\n",
       "      <td>`` archeofuturism identity evropa ''</td>\n",
       "      <td>5</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>offline_propaganda</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adl_heatmap_844</th>\n",
       "      <td>`` revolution/tradition ''</td>\n",
       "      <td>3</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>offline_propaganda</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adl_heatmap_1200</th>\n",
       "      <td>`` good night left side ''</td>\n",
       "      <td>6</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>offline_propaganda</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adl_heatmap_546</th>\n",
       "      <td>`` permanent kill list ''</td>\n",
       "      <td>5</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>offline_propaganda</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adl_heatmap_751</th>\n",
       "      <td>`` they all have to go back ''</td>\n",
       "      <td>8</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>offline_propaganda</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adl_heatmap_603</th>\n",
       "      <td>`` better dead than red ``</td>\n",
       "      <td>6</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>offline_propaganda</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adl_heatmap_568</th>\n",
       "      <td>`` wake up north idaho ! ! ''</td>\n",
       "      <td>8</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>adl_heatmap</td>\n",
       "      <td>offline_propaganda</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  word_count  \\\n",
       "id                                                                   \n",
       "adl_heatmap_174                        `` cleansing ''           3   \n",
       "adl_heatmap_1205                     `` anti antifa ''           4   \n",
       "adl_heatmap_881      `` our revolution is tradition ''           6   \n",
       "adl_heatmap_168   `` archeofuturism identity evropa ''           5   \n",
       "adl_heatmap_844             `` revolution/tradition ''           3   \n",
       "adl_heatmap_1200            `` good night left side ''           6   \n",
       "adl_heatmap_546              `` permanent kill list ''           5   \n",
       "adl_heatmap_751         `` they all have to go back ''           8   \n",
       "adl_heatmap_603             `` better dead than red ``           6   \n",
       "adl_heatmap_568          `` wake up north idaho ! ! ''           8   \n",
       "\n",
       "                      dataset       source              domain timestamp  \n",
       "id                                                                        \n",
       "adl_heatmap_174   adl_heatmap  adl_heatmap  offline_propaganda       NaT  \n",
       "adl_heatmap_1205  adl_heatmap  adl_heatmap  offline_propaganda       NaT  \n",
       "adl_heatmap_881   adl_heatmap  adl_heatmap  offline_propaganda       NaT  \n",
       "adl_heatmap_168   adl_heatmap  adl_heatmap  offline_propaganda       NaT  \n",
       "adl_heatmap_844   adl_heatmap  adl_heatmap  offline_propaganda       NaT  \n",
       "adl_heatmap_1200  adl_heatmap  adl_heatmap  offline_propaganda       NaT  \n",
       "adl_heatmap_546   adl_heatmap  adl_heatmap  offline_propaganda       NaT  \n",
       "adl_heatmap_751   adl_heatmap  adl_heatmap  offline_propaganda       NaT  \n",
       "adl_heatmap_603   adl_heatmap  adl_heatmap  offline_propaganda       NaT  \n",
       "adl_heatmap_568   adl_heatmap  adl_heatmap  offline_propaganda       NaT  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View short posts across domains\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "for domain in ws_data.domain.unique():\n",
    "    print(domain)\n",
    "    domain_data = ws_data.query('domain==@domain')\n",
    "    short = domain_data[domain_data.text.str.split().str.len() <= 10]\n",
    "    display(short.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4817e2d-323d-495a-aebd-331fd510f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View distribution of post length overall\n",
    "import plotly.express as px\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "lengths = data.text.str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1b546-92c6-454f-8d77-01cfe1d30741",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['length'] = lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09b7cc7-7ded-408f-8030-23c9f0709d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "sampled = lengths.sample(int(1e6))\n",
    "sampled[sampled < 200].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e53b7-b48c-47ed-9e5b-68fd0cb79001",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.domain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b57275-8f58-4192-bd53-add433be25bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lengths across domains\n",
    "s = data[data.length < 100].sample(int(1e6))\n",
    "# s.hist(column='length')\n",
    "px.histogram(s, x='length', color='domain', barmode='overlay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78c222b-3ce0-409c-894b-c2be1291dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lengths across non-forum domains\n",
    "s = data.query('length < 100 and domain != \"forum\"')\n",
    "# s.hist(column='length')\n",
    "px.histogram(s, x='length', color='domain', barmode='overlay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa545273-9159-4b56-b7d3-c849baed2ad4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdf = lengths.value_counts().sort_index().cumsum()/len(lengths)\n",
    "cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce7f06-6377-4762-adcc-89bb507fca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(cdf[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa014d82-19f9-4669-af07-eb15d490f69c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cdfs = {domain: data[data.domain==domain]['length'].value_counts().sort_index().cumsum()/len(data) for domain in data.domain.unique()}\n",
    "# cdfs = pd.concat([pd.DataFrame(\n",
    "#     {'cumsum': data[data.domain==domain]['length'].value_counts().sort_index().cumsum()/len(data), 'domain': domain}) for domain in data.domain.unique()\n",
    "#                  ])\n",
    "cdfs = pd.concat([pd.DataFrame(\n",
    "    data[data.domain==domain]['length'].value_counts().sort_index().cumsum()/len(data[data.domain==domain])).assign(domain=domain).rename_axis('value').reset_index() for domain in data.domain.unique()\n",
    "                 ])\n",
    "cdfs.info()\n",
    "cdfs[cdfs.value <= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63d4842-2733-48b3-93e8-c4af1f9c32f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.line(cdfs[cdfs.value <= 100], x='value', y='length', color='domain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a653383b-955d-4128-ac64-9cc4add3adb7",
   "metadata": {},
   "source": [
    "## Check Patriot Front chat posts for white supremacist ideology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea90b54-e8f5-40ee-b68b-763cca297e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'172809042299715584'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "758a85d6-9c38-45b8-9f98-9af06518dcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 229305 entries, calderon2021_0 to stormfront_99972\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count   Dtype              \n",
      "---  ------      --------------   -----              \n",
      " 0   text        229305 non-null  object             \n",
      " 1   word_count  229305 non-null  int64              \n",
      " 2   dataset     229305 non-null  object             \n",
      " 3   source      229305 non-null  object             \n",
      " 4   domain      229305 non-null  object             \n",
      " 5   timestamp   229051 non-null  datetime64[ns, UTC]\n",
      " 6   num_words   229305 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 14.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load white supremacist corpus\n",
    "import pandas as pd\n",
    "\n",
    "path = '../tmp/white_supremacist_train_corpus.pkl'\n",
    "data = pd.read_pickle(path)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b672b39f-2c6b-499f-b72e-e15949ce25ac",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "data.query('domain==\"chat\"').sample(30)[['text', 'dataset']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd7f49f-01d2-4f36-8880-06543647eca6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Corpus stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d923a9-d2e9-4eaf-b86e-e580c2017f91",
   "metadata": {},
   "source": [
    "## Full corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e53b6f94-e9d3-4fc1-9107-eca3ca86e0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4370588 entries, qian2018_0 to rieger2021_white_supremacist_4447\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Dtype              \n",
      "---  ------      -----              \n",
      " 0   text        object             \n",
      " 1   word_count  int64              \n",
      " 2   dataset     object             \n",
      " 3   source      object             \n",
      " 4   domain      object             \n",
      " 5   timestamp   datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(4)\n",
      "memory usage: 233.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import pandas as pd\n",
    "\n",
    "path = '../tmp/white_supremacist_corpus.pkl'\n",
    "data = pd.read_pickle(path)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb7e6e6c-1f21-4918-804d-75ce79c66df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.917245688680794"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.word_count.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e95f6a55-e02b-4e8a-b984-3d122d729dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4370588.000\n",
       "mean          52.917\n",
       "std          169.804\n",
       "min            1.000\n",
       "25%           10.000\n",
       "50%           21.000\n",
       "75%           48.000\n",
       "max        81177.000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.word_count.describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "705e44f3-8ebb-400d-8bca-517fd3603024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4370588.000\n",
       "mean         262.609\n",
       "std          872.094\n",
       "min            1.000\n",
       "25%           48.000\n",
       "50%          101.000\n",
       "75%          236.000\n",
       "max       444195.000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text.str.len().describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b1aeaba-22d3-46e8-bb9d-282d771e81a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tweet', 'chat', 'forum', 'long-form', 'offline_propaganda'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.domain.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1481c701-7772-4952-8c47-24b095908218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     43016.000\n",
       "mean       1390.434\n",
       "std        4295.981\n",
       "min           2.000\n",
       "25%         160.000\n",
       "50%         637.000\n",
       "75%        1546.000\n",
       "max      444195.000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.domain=='long-form'].text.str.len().describe().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebf377e-ee7f-4d0c-bc93-af643d6f6883",
   "metadata": {},
   "source": [
    "## Evaluation corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2af76e0-b047-45ff-ae1e-4708b1373afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 762 entries, hatecheck_identity_nonhate_977 to hatecheck_identity_nonhate_2775\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   text        762 non-null    object\n",
      " 1   word_count  762 non-null    int64 \n",
      " 2   dataset     762 non-null    object\n",
      " 3   source      762 non-null    object\n",
      " 4   domain      762 non-null    object\n",
      " 5   label       762 non-null    int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 41.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import pandas as pd\n",
    "\n",
    "# path = '../tmp/annotated_corpus.pkl'\n",
    "# path = '../tmp/domain_test_corpus.pkl'\n",
    "path = '../tmp/bias_test_identity_nonhate_corpus.pkl'\n",
    "annotated = pd.read_pickle(path)\n",
    "annotated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c616737-3bb0-4dff-894c-a449c854d184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adl_heatmap    1798\n",
       "Name: dataset, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated.dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "374085b0-17aa-4e45-ac33-0f09b35c8970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not ws</th>\n",
       "      <th>ws</th>\n",
       "      <th>All</th>\n",
       "      <th>ws proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adl_heatmap</th>\n",
       "      <td>143</td>\n",
       "      <td>1655</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.920467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>143</td>\n",
       "      <td>1655</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.920467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             not ws    ws   All  ws proportion\n",
       "dataset                                       \n",
       "adl_heatmap     143  1655  1798       0.920467\n",
       "All             143  1655  1798       0.920467"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_distro = pd.crosstab(annotated.dataset, annotated.label, margins=True)\n",
    "dataset_distro.columns = ['not ws', 'ws', 'All']\n",
    "dataset_distro['ws proportion'] = dataset_distro['ws']/dataset_distro['All']\n",
    "dataset_distro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c9142b3-82ac-4058-9b90-5a30af0dd795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5162 entries, rieger2021_1 to rieger2021_6000\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   text     5162 non-null   object\n",
      " 1   dataset  5162 non-null   object\n",
      " 2   source   5162 non-null   object\n",
      " 3   domain   5162 non-null   object\n",
      " 4   label    5162 non-null   int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 242.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    4794\n",
       "1     368\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at Rieger+2021\n",
    "rieger2021 = annotated[annotated.dataset=='rieger2021']\n",
    "rieger2021.info()\n",
    "rieger2021.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f13b2533-989e-43e2-b0bd-418c98523fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 57645 entries, alatawi2021_0 to siegel2021_9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   text        57645 non-null  object\n",
      " 1   word_count  57645 non-null  int64 \n",
      " 2   dataset     57645 non-null  object\n",
      " 3   source      57645 non-null  object\n",
      " 4   domain      57645 non-null  object\n",
      " 5   label       57645 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Look at 5x annotated corpus\n",
    "import pandas as pd\n",
    "\n",
    "path = '../tmp/annotated_5x_corpus_train70.pkl'\n",
    "annotated_5x = pd.read_pickle(path)\n",
    "annotated_5x.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f336ab-1735-46d4-a919-1e93dee7ac3a",
   "metadata": {},
   "source": [
    "## Training corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209907d8-cf2b-4a14-bacd-6778da8af9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4370588 entries, qian2018_0 to rieger2021_white_supremacist_4447\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Dtype              \n",
      "---  ------      -----              \n",
      " 0   text        object             \n",
      " 1   word_count  int64              \n",
      " 2   dataset     object             \n",
      " 3   source      object             \n",
      " 4   domain      object             \n",
      " 5   timestamp   datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(4)\n",
      "memory usage: 233.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "231279479"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "import pandas as pd\n",
    "\n",
    "# path = '../tmp/white_supremacist_train_6topic_corpus.pkl'\n",
    "path = '../tmp/white_supremacist_corpus.pkl' # fulltext, for Ahmad\n",
    "# path = '../tmp/neutral_train_6topic_corpus.pkl'\n",
    "# path = '../tmp/antiracist_train_6topic_corpus.pkl'\n",
    "# path = '../tmp/domain_test_corpus.pkl'\n",
    "data = pd.read_pickle(path)\n",
    "# path = '../data/corpora/white_supremacist_corpus.json'\n",
    "# data = pd.read_json(path, orient='table')\n",
    "# print(len(data))\n",
    "# data.columns\n",
    "\n",
    "# for i in [2, 6, 15]:\n",
    "#     print(f'{i}_topic')\n",
    "#     path = f'../tmp/white_supremacist_train_{i}topic_corpus.pkl'\n",
    "#     data = pd.read_pickle(path)\n",
    "#     data.info()\n",
    "#     data.word_count.sum()\n",
    "#     print()\n",
    "    \n",
    "data.info()\n",
    "data.word_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a62deee-debe-4ac3-9d23-38c5d326f0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_post_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chat</th>\n",
       "      <td>1622</td>\n",
       "      <td>46530</td>\n",
       "      <td>28.686806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forum</th>\n",
       "      <td>100000</td>\n",
       "      <td>8412581</td>\n",
       "      <td>84.125810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long-form</th>\n",
       "      <td>7668</td>\n",
       "      <td>2081996</td>\n",
       "      <td>271.517475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <td>9552</td>\n",
       "      <td>176244</td>\n",
       "      <td>18.451005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>118842</td>\n",
       "      <td>10717351</td>\n",
       "      <td>90.181510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           post_count  word_count  avg_post_length\n",
       "chat             1622       46530        28.686806\n",
       "forum          100000     8412581        84.125810\n",
       "long-form        7668     2081996       271.517475\n",
       "tweet            9552      176244        18.451005\n",
       "total          118842    10717351        90.181510"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Post and word counts total and per domain\n",
    "stats = data.groupby('domain').agg({'word_count': ['count', 'sum', 'mean']})\n",
    "stats.columns = ['post_count', 'word_count', 'avg_post_length']\n",
    "stats\n",
    "\n",
    "total = pd.DataFrame({'post_count': len(data), 'word_count': data.word_count.sum(), 'avg_post_length': data.word_count.mean()}, index=['total'])\n",
    "total\n",
    "\n",
    "pd.concat([stats,total])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37582393-894f-4ec2-b591-0f384adffad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adl_heatmap</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_white_supremacist</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calderon2021</th>\n",
       "      <td>2005-01-17 00:00:00+00:00</td>\n",
       "      <td>2017-02-18 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elsherief2021</th>\n",
       "      <td>2009-09-17 20:49:02+00:00</td>\n",
       "      <td>2017-12-30 04:21:58+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ironmarch</th>\n",
       "      <td>2011-09-13 01:06:06+00:00</td>\n",
       "      <td>2017-11-21 03:41:24+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jokubausaite2020</th>\n",
       "      <td>2014-03-20 00:56:47+00:00</td>\n",
       "      <td>2019-05-22 23:21:39+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>papasavva2020</th>\n",
       "      <td>2017-06-13 11:13:02+00:00</td>\n",
       "      <td>2019-11-01 09:25:21+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront</th>\n",
       "      <td>2017-05-17 02:36:29.207000+00:00</td>\n",
       "      <td>2018-03-05 11:55:40.097000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pruden2022</th>\n",
       "      <td>1968-01-01 00:00:00+00:00</td>\n",
       "      <td>2012-01-01 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qian2018</th>\n",
       "      <td>2009-07-12 19:13:08+00:00</td>\n",
       "      <td>2017-12-31 03:23:39+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rieger2021_white_supremacist</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siegel2021_white_supremacist</th>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stormfront</th>\n",
       "      <td>2001-09-11 22:35:00+00:00</td>\n",
       "      <td>2017-09-14 16:59:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     timestamp  \\\n",
       "                                                           min   \n",
       "dataset                                                          \n",
       "adl_heatmap                                                NaT   \n",
       "alatawi2021_white_supremacist                              NaT   \n",
       "calderon2021                         2005-01-17 00:00:00+00:00   \n",
       "elsherief2021                        2009-09-17 20:49:02+00:00   \n",
       "ironmarch                            2011-09-13 01:06:06+00:00   \n",
       "jokubausaite2020                     2014-03-20 00:56:47+00:00   \n",
       "papasavva2020                        2017-06-13 11:13:02+00:00   \n",
       "patriotfront                  2017-05-17 02:36:29.207000+00:00   \n",
       "pruden2022                           1968-01-01 00:00:00+00:00   \n",
       "qian2018                             2009-07-12 19:13:08+00:00   \n",
       "rieger2021_white_supremacist                               NaT   \n",
       "siegel2021_white_supremacist                               NaT   \n",
       "stormfront                           2001-09-11 22:35:00+00:00   \n",
       "\n",
       "                                                                \n",
       "                                                           max  \n",
       "dataset                                                         \n",
       "adl_heatmap                                                NaT  \n",
       "alatawi2021_white_supremacist                              NaT  \n",
       "calderon2021                         2017-02-18 00:00:00+00:00  \n",
       "elsherief2021                        2017-12-30 04:21:58+00:00  \n",
       "ironmarch                            2017-11-21 03:41:24+00:00  \n",
       "jokubausaite2020                     2019-05-22 23:21:39+00:00  \n",
       "papasavva2020                        2019-11-01 09:25:21+00:00  \n",
       "patriotfront                  2018-03-05 11:55:40.097000+00:00  \n",
       "pruden2022                           2012-01-01 00:00:00+00:00  \n",
       "qian2018                             2017-12-31 03:23:39+00:00  \n",
       "rieger2021_white_supremacist                               NaT  \n",
       "siegel2021_white_supremacist                               NaT  \n",
       "stormfront                           2017-09-14 16:59:00+00:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max and min dates for each dataset\n",
    "data.groupby('dataset').agg({'timestamp': ['min', 'max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f6775b-ca06-45a7-91f5-4fe8ce9c86ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4367140\n",
      "4366871\n"
     ]
    }
   ],
   "source": [
    "# Investigate date ranges\n",
    "print(len(train_ws_data))\n",
    "print(train_ws_data.timestamp.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433700c2-aaf5-401d-af3d-a16862422a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = 'plotly'\n",
    "train_ws_data.timestamp.sample(int(1e6)).hist()\n",
    "# data.timestamp.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1388660e-bdfe-4c6e-b3d7-76862f6b9bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1968-01-01 00:00:00+0000', tz='UTC')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ws_data.timestamp.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23434038-e176-4ba5-b56c-89fb077e73b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-11-01 09:25:21+0000', tz='UTC')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ws_data.timestamp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d88a7839-8dba-4b3f-90b4-68e8d27048ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3322922\n",
      "4367140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7608920254445701"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of content that is from 2017-2019\n",
    "start_date = pd.Timestamp(year=2017, month=1, day=1, tz='utc')\n",
    "samp = train_ws_data.query('timestamp > @start_date')\n",
    "print(len(samp))\n",
    "print(len(train_ws_data))\n",
    "len(samp)/len(train_ws_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04278ce7-15e8-4031-b813-92024518af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp(year=2000, month=1, day=1, tz='utc')\n",
    "data.query('timestamp > @start_date').timestamp.sample(int(1e5)).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a89ab-87e9-4418-b364-b5854a3e2b56",
   "metadata": {},
   "source": [
    "## Data table on full white supremacist corpus \n",
    "For this paper, also for white supremacist propaganda paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87803056-1501-4fed-92fd-28b5256893d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4370588 entries, qian2018_0 to rieger2021_white_supremacist_4447\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Dtype              \n",
      "---  ------      -----              \n",
      " 0   text        object             \n",
      " 1   word_count  int64              \n",
      " 2   dataset     object             \n",
      " 3   source      object             \n",
      " 4   domain      object             \n",
      " 5   timestamp   datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(4)\n",
      "memory usage: 233.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "231279479"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "import pandas as pd\n",
    "\n",
    "# path = '../tmp/white_supremacist_train_6topic_corpus.pkl'\n",
    "path = '../tmp/white_supremacist_corpus.pkl' # fulltext, for Ahmad\n",
    "# path = '../tmp/neutral_train_6topic_corpus.pkl'\n",
    "# path = '../tmp/antiracist_train_6topic_corpus.pkl'\n",
    "# path = '../tmp/domain_test_corpus.pkl'\n",
    "data = pd.read_pickle(path)\n",
    "# path = '../data/corpora/white_supremacist_corpus.json'\n",
    "# data = pd.read_json(path, orient='table')\n",
    "# print(len(data))\n",
    "# data.columns\n",
    "\n",
    "# for i in [2, 6, 15]:\n",
    "#     print(f'{i}_topic')\n",
    "#     path = f'../tmp/white_supremacist_train_{i}topic_corpus.pkl'\n",
    "#     data = pd.read_pickle(path)\n",
    "#     data.info()\n",
    "#     data.word_count.sum()\n",
    "#     print()\n",
    "    \n",
    "data.info()\n",
    "data.word_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2140a3d-736f-4572-baea-d213422af455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4368769 entries, qian2018_0 to rieger2021_white_supremacist_4447\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Dtype              \n",
      "---  ------      -----              \n",
      " 0   text        object             \n",
      " 1   word_count  int64              \n",
      " 2   dataset     object             \n",
      " 3   source      object             \n",
      " 4   domain      object             \n",
      " 5   timestamp   datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(4)\n",
      "memory usage: 233.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>papasavva2020</th>\n",
       "      <td>2686268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stormfront</th>\n",
       "      <td>751982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jokubausaite2020</th>\n",
       "      <td>578652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ironmarch</th>\n",
       "      <td>179468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qian2018</th>\n",
       "      <td>84696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront</th>\n",
       "      <td>39578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calderon2021</th>\n",
       "      <td>26009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pruden2022</th>\n",
       "      <td>17007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elsherief2021</th>\n",
       "      <td>3480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alatawi2021_white_supremacist</th>\n",
       "      <td>1098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rieger2021_white_supremacist</th>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siegel2021_white_supremacist</th>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               dataset\n",
       "papasavva2020                  2686268\n",
       "stormfront                      751982\n",
       "jokubausaite2020                578652\n",
       "ironmarch                       179468\n",
       "qian2018                         84696\n",
       "patriotfront                     39578\n",
       "calderon2021                     26009\n",
       "pruden2022                       17007\n",
       "elsherief2021                     3480\n",
       "alatawi2021_white_supremacist     1098\n",
       "rieger2021_white_supremacist       361\n",
       "siegel2021_white_supremacist       170"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the paper\n",
    "# Filter to just datasets used in training corpus\n",
    "# exclude = ['alatawi2021_white_supremacist', 'adl_heatmap', 'rieger2021_white_supremacist', 'siegel2021_white_supremacist']\n",
    "exclude = ['adl_heatmap']\n",
    "train_ws_data = data[~data.dataset.isin(exclude)]\n",
    "train_ws_data.info()\n",
    "table = pd.DataFrame(train_ws_data.dataset.value_counts())\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c081950-c058-4489-8d82-d86aaa0b568b",
   "metadata": {},
   "source": [
    "### Find suitable examples for the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fc425bc-a2b7-4a48-8eac-39d6ce5d4808",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>dataset</th>\n",
       "      <th>source</th>\n",
       "      <th>domain</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>patriotfront_45560</th>\n",
       "      <td>again , the venue is confirmed per bristow &amp; dr but they're reserving this info until last minute . i would imagine it will be north of detroit , probably warren / pontiac area .</td>\n",
       "      <td>35</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2018-02-27 03:01:34.384000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_35231</th>\n",
       "      <td>i actually post them in the middle of the day . so ... fake news .</td>\n",
       "      <td>16</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-10-20 14:51:13.327000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_41716</th>\n",
       "      <td>i can get the symbol biggest on the top left , while retaining all the symbolistic qualities , which is what's important .</td>\n",
       "      <td>23</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-10-07 01:12:58.755000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_28202</th>\n",
       "      <td>im gonna put a poster of this in my room lol .</td>\n",
       "      <td>12</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2018-02-16 03:10:13.826000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_24209</th>\n",
       "      <td>you know , the fascist is supposed to embrace the life of struggle . likewise , jesus said to his followers to give up everything and follow him . the foxes have dens , the birds have nests , but the son of man has no place to lay his head . that sounds like a life of struggle to me .</td>\n",
       "      <td>62</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-07-22 03:48:46.473000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_19607</th>\n",
       "      <td>springfield xd / xdm / xds line is pretty good imo .</td>\n",
       "      <td>12</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-07-21 03:03:16.759000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_1193</th>\n",
       "      <td>if anyone is into rac , i've got a twitter account where i post songs daily . it's @ dailyrac</td>\n",
       "      <td>20</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-06-14 12:49:04.136000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_32168</th>\n",
       "      <td>we need to recruit tays ai to run our server .</td>\n",
       "      <td>11</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2018-02-27 00:30:32.378000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_13375</th>\n",
       "      <td>i like the declaration of war on cnn . let's do this .</td>\n",
       "      <td>13</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-07-05 04:31:15.456000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_25475</th>\n",
       "      <td>yeah it was fucking unbareable , i had to move back to the united states after that</td>\n",
       "      <td>17</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2018-02-08 18:16:39.036000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_4226</th>\n",
       "      <td>do we even know if someone is in custody ? i've heard like 4 differing stories at this point</td>\n",
       "      <td>19</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-08-13 00:36:32.289000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_25963</th>\n",
       "      <td>he shouldnt be shining his shoes he should just be back in africa</td>\n",
       "      <td>13</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2018-02-09 00:47:31.685000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_34785</th>\n",
       "      <td>lmao i ‚Äô m looking at the news article , underneath is a add for spartan armor systems targeted ads</td>\n",
       "      <td>20</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-10-23 15:01:52.824000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_5479</th>\n",
       "      <td>probably doesn't help that the following night i , unaware of the vandalism , returned from a camping trip and postered an apartment complex with imagine a muslim free america posters</td>\n",
       "      <td>31</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-07-14 01:54:35.365000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_27788</th>\n",
       "      <td>i followed him on twitter ; he ‚Äô s filipino lmao</td>\n",
       "      <td>11</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2018-02-24 15:04:34.529000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_11641</th>\n",
       "      <td>\" white sharia \" embraces post modernism's sense of irony . the thing is that some people took it too seriously .</td>\n",
       "      <td>22</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-05-23 14:03:00.286000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_20692</th>\n",
       "      <td>oh the subject of interracial dating i find that appalling and disgusting what drives someone to do that there's a difference between a shepherd and a labrador how can someone say we are all the same do we have any anti interracial posters minus the vanguard part because we're on suspension</td>\n",
       "      <td>51</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-08-24 17:02:45.540000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_40401</th>\n",
       "      <td>i suppose it's easier to love a society that is mostly made of idealized retellings over the course of several years than one that still exists , in some form or another , today .</td>\n",
       "      <td>35</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-10-09 05:35:16.465000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_41630</th>\n",
       "      <td>it's absolutely rediculous , and if they had any sense they'd drop it .</td>\n",
       "      <td>14</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-10-14 20:21:22.659000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patriotfront_9952</th>\n",
       "      <td>there are going to be weirdos that want to cling to the movement and it may have been nothing more complicated than no one really took notice and it was able to hang around</td>\n",
       "      <td>34</td>\n",
       "      <td>patriotfront</td>\n",
       "      <td>discord</td>\n",
       "      <td>chat</td>\n",
       "      <td>2017-06-26 23:45:39.292000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                   text  \\\n",
       "id                                                                                                                                                                                                                                                                                                                        \n",
       "patriotfront_45560                                                                                                                   again , the venue is confirmed per bristow & dr but they're reserving this info until last minute . i would imagine it will be north of detroit , probably warren / pontiac area .   \n",
       "patriotfront_35231                                                                                                                                                                                                                                   i actually post them in the middle of the day . so ... fake news .   \n",
       "patriotfront_41716                                                                                                                                                                           i can get the symbol biggest on the top left , while retaining all the symbolistic qualities , which is what's important .   \n",
       "patriotfront_28202                                                                                                                                                                                                                                                       im gonna put a poster of this in my room lol .   \n",
       "patriotfront_24209        you know , the fascist is supposed to embrace the life of struggle . likewise , jesus said to his followers to give up everything and follow him . the foxes have dens , the birds have nests , but the son of man has no place to lay his head . that sounds like a life of struggle to me .   \n",
       "patriotfront_19607                                                                                                                                                                                                                                                 springfield xd / xdm / xds line is pretty good imo .   \n",
       "patriotfront_1193                                                                                                                                                                                                         if anyone is into rac , i've got a twitter account where i post songs daily . it's @ dailyrac   \n",
       "patriotfront_32168                                                                                                                                                                                                                                                       we need to recruit tays ai to run our server .   \n",
       "patriotfront_13375                                                                                                                                                                                                                                               i like the declaration of war on cnn . let's do this .   \n",
       "patriotfront_25475                                                                                                                                                                                                                  yeah it was fucking unbareable , i had to move back to the united states after that   \n",
       "patriotfront_4226                                                                                                                                                                                                          do we even know if someone is in custody ? i've heard like 4 differing stories at this point   \n",
       "patriotfront_25963                                                                                                                                                                                                                                    he shouldnt be shining his shoes he should just be back in africa   \n",
       "patriotfront_34785                                                                                                                                                                                                  lmao i ‚Äô m looking at the news article , underneath is a add for spartan armor systems targeted ads   \n",
       "patriotfront_5479                                                                                                               probably doesn't help that the following night i , unaware of the vandalism , returned from a camping trip and postered an apartment complex with imagine a muslim free america posters   \n",
       "patriotfront_27788                                                                                                                                                                                                                                                     i followed him on twitter ; he ‚Äô s filipino lmao   \n",
       "patriotfront_11641                                                                                                                                                                                    \" white sharia \" embraces post modernism's sense of irony . the thing is that some people took it too seriously .   \n",
       "patriotfront_20692  oh the subject of interracial dating i find that appalling and disgusting what drives someone to do that there's a difference between a shepherd and a labrador how can someone say we are all the same do we have any anti interracial posters minus the vanguard part because we're on suspension   \n",
       "patriotfront_40401                                                                                                                  i suppose it's easier to love a society that is mostly made of idealized retellings over the course of several years than one that still exists , in some form or another , today .   \n",
       "patriotfront_41630                                                                                                                                                                                                                              it's absolutely rediculous , and if they had any sense they'd drop it .   \n",
       "patriotfront_9952                                                                                                                          there are going to be weirdos that want to cling to the movement and it may have been nothing more complicated than no one really took notice and it was able to hang around   \n",
       "\n",
       "                    word_count       dataset   source domain  \\\n",
       "id                                                             \n",
       "patriotfront_45560          35  patriotfront  discord   chat   \n",
       "patriotfront_35231          16  patriotfront  discord   chat   \n",
       "patriotfront_41716          23  patriotfront  discord   chat   \n",
       "patriotfront_28202          12  patriotfront  discord   chat   \n",
       "patriotfront_24209          62  patriotfront  discord   chat   \n",
       "patriotfront_19607          12  patriotfront  discord   chat   \n",
       "patriotfront_1193           20  patriotfront  discord   chat   \n",
       "patriotfront_32168          11  patriotfront  discord   chat   \n",
       "patriotfront_13375          13  patriotfront  discord   chat   \n",
       "patriotfront_25475          17  patriotfront  discord   chat   \n",
       "patriotfront_4226           19  patriotfront  discord   chat   \n",
       "patriotfront_25963          13  patriotfront  discord   chat   \n",
       "patriotfront_34785          20  patriotfront  discord   chat   \n",
       "patriotfront_5479           31  patriotfront  discord   chat   \n",
       "patriotfront_27788          11  patriotfront  discord   chat   \n",
       "patriotfront_11641          22  patriotfront  discord   chat   \n",
       "patriotfront_20692          51  patriotfront  discord   chat   \n",
       "patriotfront_40401          35  patriotfront  discord   chat   \n",
       "patriotfront_41630          14  patriotfront  discord   chat   \n",
       "patriotfront_9952           34  patriotfront  discord   chat   \n",
       "\n",
       "                                          timestamp  \n",
       "id                                                   \n",
       "patriotfront_45560 2018-02-27 03:01:34.384000+00:00  \n",
       "patriotfront_35231 2017-10-20 14:51:13.327000+00:00  \n",
       "patriotfront_41716 2017-10-07 01:12:58.755000+00:00  \n",
       "patriotfront_28202 2018-02-16 03:10:13.826000+00:00  \n",
       "patriotfront_24209 2017-07-22 03:48:46.473000+00:00  \n",
       "patriotfront_19607 2017-07-21 03:03:16.759000+00:00  \n",
       "patriotfront_1193  2017-06-14 12:49:04.136000+00:00  \n",
       "patriotfront_32168 2018-02-27 00:30:32.378000+00:00  \n",
       "patriotfront_13375 2017-07-05 04:31:15.456000+00:00  \n",
       "patriotfront_25475 2018-02-08 18:16:39.036000+00:00  \n",
       "patriotfront_4226  2017-08-13 00:36:32.289000+00:00  \n",
       "patriotfront_25963 2018-02-09 00:47:31.685000+00:00  \n",
       "patriotfront_34785 2017-10-23 15:01:52.824000+00:00  \n",
       "patriotfront_5479  2017-07-14 01:54:35.365000+00:00  \n",
       "patriotfront_27788 2018-02-24 15:04:34.529000+00:00  \n",
       "patriotfront_11641 2017-05-23 14:03:00.286000+00:00  \n",
       "patriotfront_20692 2017-08-24 17:02:45.540000+00:00  \n",
       "patriotfront_40401 2017-10-09 05:35:16.465000+00:00  \n",
       "patriotfront_41630 2017-10-14 20:21:22.659000+00:00  \n",
       "patriotfront_9952  2017-06-26 23:45:39.292000+00:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# dataset = 'stormfront'\n",
    "# dataset = 'jokubausaite2020'\n",
    "# dataset = 'ironmarch'\n",
    "# dataset = 'qian2018'\n",
    "dataset = 'patriotfront'\n",
    "# dataset = 'calderon2021'\n",
    "# dataset = 'pruden2022'\n",
    "# dataset = 'elsherief2021'\n",
    "# for dataset in table.index.tolist()[:1]:\n",
    "    # print(dataset)\n",
    "# s = data.query('dataset==@dataset and word_count > 10 and word_count < 25').sample(20)\n",
    "s = data.query('dataset==@dataset and word_count > 10').sample(20)\n",
    "display(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d885aef-64e5-4268-bf01-5d4668d9aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_ids = [\n",
    "    'papasavva2020_192385',\n",
    "    # 'papsavva2020_2858805',\n",
    "    # 'papsavva2020_2464605',\n",
    "    # 'papsavva2020_1884143',\n",
    "    # 'papsavva2020_1260643',\n",
    "    # 'papsavva2020_2585515',\n",
    "    # 'stormfront_371232',\n",
    "    # 'stormfront_203518',\n",
    "    # 'stormfront_198889',\n",
    "    # 'stormfront_186354',\n",
    "    'stormfront_196266',\n",
    "    # 'jokubausaite2020_324206',\n",
    "    'jokubausaite2020_640881',\n",
    "    'jokubausaite2020_528383',\n",
    "    # 'ironmarch_12255',\n",
    "    # 'ironmarch_97263',\n",
    "    # 'ironmarch_17979',\n",
    "    'ironmarch_29999',\n",
    "    'ironmarch_99916',\n",
    "    'qian2018_53842',\n",
    "    'patriotfront_27319',\n",
    "    'patriotfront_25963',\n",
    "    'patriotfront_20692',\n",
    "    # 'calderon2021_daily_stormer_13493',\n",
    "    'calderon2021_daily_stormer_2787',\n",
    "    'pruden2022_breivik_manifesto_91',\n",
    "    'elsherief2021_3057',\n",
    "    'elsherief2021_503',\n",
    "    'elsherief2021_5376',\n",
    "    'elsherief2021_692',\n",
    "    'elsherief2021_4814',\n",
    "]\n",
    "\n",
    "data.loc[example_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e563bd92-98fb-4273-8ae0-5c4a8774e6c0",
   "metadata": {},
   "source": [
    "# Compare corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad437136-6229-453a-a957-f0a8d6d6f4d7",
   "metadata": {},
   "source": [
    "## Compare LDA filtering (2topic vs 6topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0bd4f72-e141-4b26-8dd9-fa96d25ab3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 118842 entries, calderon2021_daily_stormer_0 to stormfront_99968\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count   Dtype              \n",
      "---  ------      --------------   -----              \n",
      " 0   text        118842 non-null  object             \n",
      " 1   word_count  118842 non-null  int64              \n",
      " 2   dataset     118842 non-null  object             \n",
      " 3   source      118842 non-null  object             \n",
      " 4   domain      118842 non-null  object             \n",
      " 5   timestamp   118810 non-null  datetime64[ns, UTC]\n",
      " 6   topic       118842 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 7.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4chan                               70250\n",
       "stormfront                          24120\n",
       "twitter                              9552\n",
       "ironmarch                            5630\n",
       "daily_stormer                        4435\n",
       "breivik_manifesto                    3156\n",
       "discord                              1622\n",
       "raspail_camp_of_the_saints_book        30\n",
       "camus_the_great_replacement_book       25\n",
       "lane_white_genocide_manifesto          15\n",
       "powell_rivers_of_blood_speech           7\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load 6topic\n",
    "path = '../tmp/white_supremacist_train_6topic_corpus.pkl'\n",
    "data_6topic = pd.read_pickle(path)\n",
    "data_6topic.info()\n",
    "data_6topic.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba64a5c7-407e-4ac5-9693-b64491633d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 106165 entries, calderon2021_daily_stormer_1002 to stormfront_9993\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count   Dtype              \n",
      "---  ------      --------------   -----              \n",
      " 0   text        106165 non-null  object             \n",
      " 1   word_count  106165 non-null  int64              \n",
      " 2   dataset     106165 non-null  object             \n",
      " 3   source      106165 non-null  object             \n",
      " 4   domain      106165 non-null  object             \n",
      " 5   timestamp   106155 non-null  datetime64[ns, UTC]\n",
      " 6   topic       106165 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 6.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4chan                              64685\n",
       "stormfront                         32770\n",
       "twitter                             3638\n",
       "ironmarch                           2545\n",
       "daily_stormer                       1820\n",
       "discord                              564\n",
       "breivik_manifesto                    134\n",
       "lane_white_genocide_manifesto          8\n",
       "raspail_camp_of_the_saints_book        1\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load 2topic\n",
    "path = '../tmp/white_supremacist_train_2topic_corpus.pkl'\n",
    "data_2topic = pd.read_pickle(path)\n",
    "data_2topic.info()\n",
    "data_2topic.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70363b95-555e-463e-8fea-36ebc06d8df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 150733 entries, calderon2021_daily_stormer_0 to stormfront_99947\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count   Dtype              \n",
      "---  ------      --------------   -----              \n",
      " 0   text        150733 non-null  object             \n",
      " 1   word_count  150733 non-null  int64              \n",
      " 2   dataset     150733 non-null  object             \n",
      " 3   source      150733 non-null  object             \n",
      " 4   domain      150733 non-null  object             \n",
      " 5   timestamp   150630 non-null  datetime64[ns, UTC]\n",
      " 6   topic       150733 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 9.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4chan                               73317\n",
       "twitter                             27548\n",
       "stormfront                          21398\n",
       "daily_stormer                       11101\n",
       "breivik_manifesto                    6354\n",
       "discord                              5437\n",
       "ironmarch                            5285\n",
       "raspail_camp_of_the_saints_book       124\n",
       "camus_the_great_replacement_book      112\n",
       "powell_rivers_of_blood_speech          32\n",
       "lane_white_genocide_manifesto          25\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load 15topic\n",
    "path = '../tmp/white_supremacist_train_15topic_corpus.pkl'\n",
    "data_15topic = pd.read_pickle(path)\n",
    "data_15topic.info()\n",
    "data_15topic.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "274ec282-9cf0-4855-a195-5e288d5ca66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>6</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4chan</th>\n",
       "      <td>64685.0</td>\n",
       "      <td>70250</td>\n",
       "      <td>73317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stormfront</th>\n",
       "      <td>32770.0</td>\n",
       "      <td>24120</td>\n",
       "      <td>21398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter</th>\n",
       "      <td>3638.0</td>\n",
       "      <td>9552</td>\n",
       "      <td>27548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ironmarch</th>\n",
       "      <td>2545.0</td>\n",
       "      <td>5630</td>\n",
       "      <td>5285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daily_stormer</th>\n",
       "      <td>1820.0</td>\n",
       "      <td>4435</td>\n",
       "      <td>11101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discord</th>\n",
       "      <td>564.0</td>\n",
       "      <td>1622</td>\n",
       "      <td>5437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breivik_manifesto</th>\n",
       "      <td>134.0</td>\n",
       "      <td>3156</td>\n",
       "      <td>6354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lane_white_genocide_manifesto</th>\n",
       "      <td>8.0</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raspail_camp_of_the_saints_book</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>camus_the_great_replacement_book</th>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>powell_rivers_of_blood_speech</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       2      6      15\n",
       "4chan                             64685.0  70250  73317\n",
       "stormfront                        32770.0  24120  21398\n",
       "twitter                            3638.0   9552  27548\n",
       "ironmarch                          2545.0   5630   5285\n",
       "daily_stormer                      1820.0   4435  11101\n",
       "discord                             564.0   1622   5437\n",
       "breivik_manifesto                   134.0   3156   6354\n",
       "lane_white_genocide_manifesto         8.0     15     25\n",
       "raspail_camp_of_the_saints_book       1.0     30    124\n",
       "camus_the_great_replacement_book      NaN     25    112\n",
       "powell_rivers_of_blood_speech         NaN      7     32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([data_2topic.source.value_counts(), data_6topic.source.value_counts(),\n",
    "          data_15topic.source.value_counts()], axis=1, keys=[2, 6, 15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9531266-e76e-4cfd-b5ea-78159700897c",
   "metadata": {},
   "source": [
    "## Compare neutral+antiracist vs neutral_antiracist_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c66c954d-12cc-4f12-8779-302bbfef68b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246851\n",
      "237465\n"
     ]
    }
   ],
   "source": [
    "# Load corpora\n",
    "import pandas as pd\n",
    "\n",
    "neutral_fpath = '../tmp/neutral_train_corpus.pkl'\n",
    "antiracist_fpath = '../tmp/antiracist_train_corpus.pkl'\n",
    "neutral_antiracist_size_fpath = '../tmp/neutral_antiracist_size_corpus.pkl'\n",
    "\n",
    "neutral = pd.read_pickle(neutral_fpath)\n",
    "antiracist = pd.read_pickle(antiracist_fpath)\n",
    "neutral_antiracist_size = pd.read_pickle(neutral_antiracist_size_fpath)\n",
    "print(len(neutral) + len(antiracist))\n",
    "print(len(neutral_antiracist_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34920a7-3df5-4d12-9d9c-3c8bd453df03",
   "metadata": {},
   "source": [
    "## Compare train/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28674485-1e8a-4fc0-a6f3-3f597fc3b56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4935 entries, alatawi2021_4 to rieger2021_5997\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   text        4935 non-null   object\n",
      " 1   word_count  4935 non-null   int64 \n",
      " 2   dataset     4935 non-null   object\n",
      " 3   source      4935 non-null   object\n",
      " 4   domain      4935 non-null   object\n",
      " 5   label       4935 non-null   int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 269.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load annotations_5x test split\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "fpath = '../tmp/annotated_5x_corpus_test30.pkl'\n",
    "with open(fpath, 'rb') as f:\n",
    "    annotations_5x_test = pickle.load(f)\n",
    "annotations_5x_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbce332a-aa15-48b4-8c46-d1ad79feaa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 57645 entries, alatawi2021_0 to siegel2021_9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   text        57645 non-null  object\n",
      " 1   word_count  57645 non-null  int64 \n",
      " 2   dataset     57645 non-null  object\n",
      " 3   source      57645 non-null  object\n",
      " 4   domain      57645 non-null  object\n",
      " 5   label       57645 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load annotations_5x train split (just to confirm it doesn't have overlap with annotations_5x_test\n",
    "fpath = '../tmp/annotated_5x_corpus_train70.pkl'\n",
    "with open(fpath, 'rb') as f:\n",
    "    annotations_5x_train = pickle.load(f)\n",
    "annotations_5x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865130ff-6fb6-4dda-9c90-1ff2a028fd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11818 entries, rieger2021_4314 to alatawi2021_501\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   text        11818 non-null  object\n",
      " 1   word_count  11818 non-null  int64 \n",
      " 2   dataset     11818 non-null  object\n",
      " 3   source      11818 non-null  object\n",
      " 4   domain      11818 non-null  object\n",
      " 5   label       11818 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 646.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load regular annotations training split\n",
    "\n",
    "fpath = '../tmp/annotated_corpus_train70.pkl'\n",
    "with open(fpath, 'rb') as f:\n",
    "    annotations_train = pickle.load(f)\n",
    "annotations_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce24052-b1cc-4d93-bbf4-c5c5f14a0b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5065 entries, rieger2021_4694 to siegel2021_8429\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   text        5065 non-null   object\n",
      " 1   word_count  5065 non-null   int64 \n",
      " 2   dataset     5065 non-null   object\n",
      " 3   source      5065 non-null   object\n",
      " 4   domain      5065 non-null   object\n",
      " 5   label       5065 non-null   int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 277.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load regular annotations test split that onlyannotated models used\n",
    "\n",
    "fpath = '../tmp/annotated_corpus_test30.pkl'\n",
    "with open(fpath, 'rb') as f:\n",
    "    annotations_test = pickle.load(f)\n",
    "annotations_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85ae69b4-de6b-4d29-abf6-7b2b02ee3955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(annotations_train.index).intersection(set(annotations_test.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff8b986c-b202-4350-8283-96fb0445ddfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(annotations_5x_train.index).intersection(set(annotations_5x_test.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "517ad60d-ede3-4ff4-b4c4-e29dafa74b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(annotations_train.index).intersection(set(annotations_5x_test.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2781401-1ff1-418d-b622-3fa57b0a69cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2997448979591837"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check annotated_5x train/test ratio\n",
    "(len(annotations_5x_test)*5)/((len(annotations_5x_test)*5)+len(annotations_5x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4c4185e-8ec9-4590-bab6-9d824b605efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check separate datasets for train/test overlap\n",
    "datasets = {}\n",
    "for name in ['alatawi2021', 'rieger2021', 'siegel2021']:\n",
    "    datasets[name] = {}\n",
    "    ds_path = f'../tmp/annotated_{name}_corpus.pkl'\n",
    "    train_path = ds_path[:-4] + '_train70.pkl'\n",
    "    test_path = ds_path[:-4] + '_test30.pkl'\n",
    "    datasets[name]['all'] = pd.read_pickle(ds_path)\n",
    "    datasets[name]['train'] = pd.read_pickle(train_path)\n",
    "    datasets[name]['test'] = pd.read_pickle(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa902454-e2f1-4b70-916f-dc6fbdac2fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alatawi2021\n",
      "0\n",
      "rieger2021\n",
      "0\n",
      "siegel2021\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check separate datasets for train/test overlap\n",
    "for name in datasets:\n",
    "    print(name)\n",
    "    print(len(set(datasets[name]['train'].index).intersection(set(annotations_test.index))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713855ff-169b-432f-8c15-9224795cce17",
   "metadata": {},
   "source": [
    "# Save out portions of corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e14d75-4886-4311-8eec-adb7cf033ef5",
   "metadata": {},
   "source": [
    "## Public portions of LDA-filtered corpora for Josh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f3d7e89-df4a-41f0-b4ba-db47656080a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load corpus\n",
    "import pandas as pd\n",
    "\n",
    "exclude_datasets = [\n",
    "    'qian2018',\n",
    "    'calderon2021',\n",
    "    'pruden2022',\n",
    "    'alatawi2021_white_supremacist',\n",
    "    'rieger2021_white_supremacist',\n",
    "    'siegel2021_white_supremacist',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be61a19d-2414-48b2-a159-68e599b9d5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 106165 entries, calderon2021_daily_stormer_1002 to stormfront_9993\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count   Dtype              \n",
      "---  ------      --------------   -----              \n",
      " 0   text        106165 non-null  object             \n",
      " 1   word_count  106165 non-null  int64              \n",
      " 2   dataset     106165 non-null  object             \n",
      " 3   source      106165 non-null  object             \n",
      " 4   domain      106165 non-null  object             \n",
      " 5   timestamp   106155 non-null  datetime64[ns, UTC]\n",
      " 6   topic       106165 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 6.5+ MB\n",
      "papasavva2020       57586\n",
      "stormfront          32770\n",
      "jokubausaite2020     7099\n",
      "qian2018             2896\n",
      "ironmarch            2545\n",
      "calderon2021         1820\n",
      "elsherief2021         742\n",
      "patriotfront          564\n",
      "pruden2022            143\n",
      "Name: dataset, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 118842 entries, calderon2021_daily_stormer_0 to stormfront_99968\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count   Dtype              \n",
      "---  ------      --------------   -----              \n",
      " 0   text        118842 non-null  object             \n",
      " 1   word_count  118842 non-null  int64              \n",
      " 2   dataset     118842 non-null  object             \n",
      " 3   source      118842 non-null  object             \n",
      " 4   domain      118842 non-null  object             \n",
      " 5   timestamp   118810 non-null  datetime64[ns, UTC]\n",
      " 6   topic       118842 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 7.3+ MB\n",
      "papasavva2020       57377\n",
      "stormfront          24120\n",
      "jokubausaite2020    12873\n",
      "qian2018             8529\n",
      "ironmarch            5630\n",
      "calderon2021         4435\n",
      "pruden2022           3233\n",
      "patriotfront         1622\n",
      "elsherief2021        1023\n",
      "Name: dataset, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# corpus_path = '../tmp/white_supremacist_corpus.pkl'\n",
    "for i in [2, 6]:\n",
    "    corpus_path = f'../tmp/white_supremacist_train_{i}topic_corpus.pkl'\n",
    "    corpus = pd.read_pickle(corpus_path)\n",
    "    corpus.info()\n",
    "    print(corpus.dataset.value_counts())\n",
    "    corpus = corpus[~corpus.dataset.isin(exclude_datasets)]\n",
    "    # outpath = f'../data/corpora/white_supremacist_train_{i}topic_public_corpus.jsonl'\n",
    "    # corpus.to_json(outpath, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5f0261-e461-4d3f-98e9-c4c6ecc7dced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "papasavva2020       2686268\n",
       "stormfront           751982\n",
       "jokubausaite2020     578652\n",
       "ironmarch            179468\n",
       "patriotfront          39578\n",
       "elsherief2021          3480\n",
       "adl_heatmap            1819\n",
       "Name: dataset, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full white supremacist public corpus\n",
    "corpus_path = '../tmp/white_supremacist_corpus.pkl'\n",
    "corpus = pd.read_pickle(corpus_path)\n",
    "corpus = corpus[~corpus.dataset.isin(exclude_datasets)]\n",
    "corpus.dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d5707d5-dfbd-4538-beed-5d1e06f765c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = f'../data/corpora/white_supremacist_public_corpus.jsonl'\n",
    "corpus.to_json(outpath, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58eae0d-3c72-4037-a63d-4885abec07b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create corpora from train/test splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc956cef-aa37-453b-9dca-6c2a06acd9ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split annotated_5x train dataset and annotated_5x_train70_singles by dataset \n",
    "So that nothing overlaps with annotated_5x_test30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fc6ff37-1e31-453f-88fc-1e695a0ef450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 59090 entries, alatawi2021_0 to siegel2021_9997\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   text        59090 non-null  object\n",
      " 1   word_count  59090 non-null  int64 \n",
      " 2   dataset     59090 non-null  object\n",
      " 3   source      59090 non-null  object\n",
      " 4   domain      59090 non-null  object\n",
      " 5   label       59090 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load annotations_5x train split (just to confirm it doesn't have overlap with annotations_5x_test\n",
    "fpath = '../tmp/annotated_5x_corpus_train70.pkl'\n",
    "with open(fpath, 'rb') as f:\n",
    "    annotations_5x_train = pickle.load(f)\n",
    "annotations_5x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c87335f2-a26f-4d43-bdeb-0b73ba05a1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "siegel2021     6798\n",
       "rieger2021     3524\n",
       "alatawi2021    1397\n",
       "Name: dataset, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that has new Siegel2021 (not just white_nationalist_info)\n",
    "annotations_5x_train.drop_duplicates().dataset.value_counts() # yes, appears to since has many examples for siegel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6cd997b-3da5-40d5-a6af-458a125ef33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by dataset\n",
    "separate = {dataset: annotations_5x_train[annotations_5x_train['dataset']==dataset] for dataset in annotations_5x_train.dataset.unique()}\n",
    "for name, data in separate.items():\n",
    "    outpath = f'../tmp/annotated_{name}_5x_corpus_train70.pkl'\n",
    "    data.to_pickle(outpath)\n",
    "    outpath = f'../data/corpora/annotated_{name}_5x_corpus_train70.json'\n",
    "    data.to_json(outpath, orient='table', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89ec05fa-2861-4c7d-9677-24ee271f699e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alatawi2021 7011\n",
      "rieger2021 17702\n",
      "siegel2021 34377\n"
     ]
    }
   ],
   "source": [
    "for name, data in separate.items():\n",
    "    print(name, len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a3a4ae-0b89-4da5-adad-550e7e08d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test set, split by dataset just to be complete (probably won't use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4e374ed-d884-4d01-b03b-4c6fb541eee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5065 entries, rieger2021_4694 to siegel2021_18927\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   text        5065 non-null   object\n",
      " 1   word_count  5065 non-null   int64 \n",
      " 2   dataset     5065 non-null   object\n",
      " 3   source      5065 non-null   object\n",
      " 4   domain      5065 non-null   object\n",
      " 5   label       5065 non-null   int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 277.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load annotations_5x test split\n",
    "fpath = '../tmp/annotated_5x_corpus_test30.pkl'\n",
    "with open(fpath, 'rb') as f:\n",
    "    annotations_5x_test = pickle.load(f)\n",
    "annotations_5x_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a6326fb-85a8-464d-bfe9-d5f03c4e5b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by dataset\n",
    "separate = {dataset: annotations_5x_test[annotations_5x_test['dataset']==dataset] for dataset in annotations_5x_test.dataset.unique()}\n",
    "for name, data in separate.items():\n",
    "    outpath = f'../tmp/annotated_{name}_5x_corpus_test30.pkl'\n",
    "    data.to_pickle(outpath)\n",
    "    outpath = f'../data/corpora/annotated_{name}_5x_corpus_test30.json'\n",
    "    data.to_json(outpath, orient='table', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "885571f1-2730-4d06-af11-87adcd3a39bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5333 entries, alatawi2021_0 to siegel2021_white_nationalist_only_9992\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   text        5333 non-null   object\n",
      " 1   word_count  5333 non-null   int64 \n",
      " 2   dataset     5333 non-null   object\n",
      " 3   source      5333 non-null   object\n",
      " 4   domain      5333 non-null   object\n",
      " 5   label       5333 non-null   int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 291.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load annotations_5x train singles to also split by data\n",
    "fpath = '../tmp/annotated_5x_train70_singles_corpus.pkl'\n",
    "with open(fpath, 'rb') as f:\n",
    "    annotated_singles_train = pickle.load(f)\n",
    "annotated_singles_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d72ae367-4ba4-4587-be99-2b50b8fb04fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alatawi2021', 'rieger2021', 'siegel2021_white_nationalist_only'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_singles_train.dataset.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f618639-2cb1-4327-974c-960091134779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by dataset\n",
    "separate = {dataset: annotated_singles_train[annotated_singles_train['dataset']==dataset] for dataset in annotated_singles_train.dataset.unique()}\n",
    "for name, data in separate.items():\n",
    "    outpath = f'../tmp/annotated_{name}_5x_train70_singles_corpus.pkl'\n",
    "    data.to_pickle(outpath)\n",
    "    outpath = f'../data/corpora/annotated_{name}_5x_train70_singles_corpus.json'\n",
    "    data.to_json(outpath, orient='table', indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30210d2e-7e52-44d7-addd-6e05e9a008ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Annotated train corpus of single examples that aren't present in annotated_5x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3b37b94-c40c-42bf-9269-23583ca068b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 59090 entries, alatawi2021_0 to siegel2021_9997\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   text        59090 non-null  object\n",
      " 1   word_count  59090 non-null  int64 \n",
      " 2   dataset     59090 non-null  object\n",
      " 3   source      59090 non-null  object\n",
      " 4   domain      59090 non-null  object\n",
      " 5   label       59090 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load annotations_5x train split\n",
    "fpath = '../tmp/annotated_5x_corpus_train70.pkl'\n",
    "with open(fpath, 'rb') as f:\n",
    "    annotations_5x_train = pickle.load(f)\n",
    "annotations_5x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75540891-9ac7-42fe-988a-a09361707e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11719"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_5x_train_singles = annotations_5x_train.drop_duplicates()\n",
    "len(annotations_5x_train_singles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcba6f66-36da-4781-9aad-3fce82ff3034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(annotations_5x_train_singles.index).intersection(set(annotations_5x_test.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d05e7e6e-9b14-4c12-b2c6-b72174522179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out\n",
    "outpath_pkl = '../tmp/annotated_5x_train70_singles_corpus.pkl'\n",
    "outpath_json = '../data/corpora/annotated_5x_train70_singles_corpus.json'\n",
    "\n",
    "annotations_5x_train_singles.to_pickle(outpath_pkl)\n",
    "annotations_5x_train_singles.to_json(outpath_json, orient='table', indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a3629c-7923-405a-8480-ea2c4e141421",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7123f4e6-1085-4836-b9bc-f1b92bc35795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 106103 entries, calderon2021_daily_stormer_1002 to stormfront_99941\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count   Dtype              \n",
      "---  ------      --------------   -----              \n",
      " 0   text        106103 non-null  object             \n",
      " 1   word_count  106103 non-null  int64              \n",
      " 2   dataset     106103 non-null  object             \n",
      " 3   source      106103 non-null  object             \n",
      " 4   domain      106103 non-null  object             \n",
      " 5   timestamp   106092 non-null  datetime64[ns, UTC]\n",
      " 6   topic       106103 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 6.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_post_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chat</th>\n",
       "      <td>564</td>\n",
       "      <td>13822</td>\n",
       "      <td>24.507092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forum</th>\n",
       "      <td>100000</td>\n",
       "      <td>8662959</td>\n",
       "      <td>86.629590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long-form</th>\n",
       "      <td>1901</td>\n",
       "      <td>607189</td>\n",
       "      <td>319.405050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <td>3638</td>\n",
       "      <td>68771</td>\n",
       "      <td>18.903518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>106103</td>\n",
       "      <td>9352741</td>\n",
       "      <td>88.147753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           post_count  word_count  avg_post_length\n",
       "chat              564       13822        24.507092\n",
       "forum          100000     8662959        86.629590\n",
       "long-form        1901      607189       319.405050\n",
       "tweet            3638       68771        18.903518\n",
       "total          106103     9352741        88.147753"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 163451 entries, twitter_match_0 to news_match_3765\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count   Dtype              \n",
      "---  ------      --------------   -----              \n",
      " 0   text        163451 non-null  object             \n",
      " 1   word_count  163451 non-null  int64              \n",
      " 2   dataset     163451 non-null  object             \n",
      " 3   source      163451 non-null  object             \n",
      " 4   domain      163451 non-null  object             \n",
      " 5   timestamp   160982 non-null  datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(4)\n",
      "memory usage: 8.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_post_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chat</th>\n",
       "      <td>2469</td>\n",
       "      <td>14043</td>\n",
       "      <td>5.687728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forum</th>\n",
       "      <td>150831</td>\n",
       "      <td>6882015</td>\n",
       "      <td>45.627325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long-form</th>\n",
       "      <td>3765</td>\n",
       "      <td>3237212</td>\n",
       "      <td>859.817264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <td>6386</td>\n",
       "      <td>127274</td>\n",
       "      <td>19.930160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>163451</td>\n",
       "      <td>10260544</td>\n",
       "      <td>62.774434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           post_count  word_count  avg_post_length\n",
       "chat             2469       14043         5.687728\n",
       "forum          150831     6882015        45.627325\n",
       "long-form        3765     3237212       859.817264\n",
       "tweet            6386      127274        19.930160\n",
       "total          163451    10260544        62.774434"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 87807 entries, reddit_antiracist_0 to medium_antiracist_3679\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype              \n",
      "---  ------      --------------  -----              \n",
      " 0   text        87807 non-null  object             \n",
      " 1   word_count  87807 non-null  int64              \n",
      " 2   dataset     87807 non-null  object             \n",
      " 3   source      87807 non-null  object             \n",
      " 4   domain      87807 non-null  object             \n",
      " 5   timestamp   87807 non-null  datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(4)\n",
      "memory usage: 4.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_post_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>forum</th>\n",
       "      <td>82349</td>\n",
       "      <td>3870606</td>\n",
       "      <td>47.002465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long-form</th>\n",
       "      <td>1881</td>\n",
       "      <td>1589029</td>\n",
       "      <td>844.778841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <td>3577</td>\n",
       "      <td>65480</td>\n",
       "      <td>18.305843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>87807</td>\n",
       "      <td>5525115</td>\n",
       "      <td>62.923400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           post_count  word_count  avg_post_length\n",
       "forum           82349     3870606        47.002465\n",
       "long-form        1881     1589029       844.778841\n",
       "tweet            3577       65480        18.305843\n",
       "total           87807     5525115        62.923400"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load white supremacist corpus\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "path = '../tmp/white_supremacist_train_corpus.pkl'\n",
    "ws_data = pd.read_pickle(path)\n",
    "ws_data.info()\n",
    "\n",
    "# Post and word counts total and per domain\n",
    "stats = ws_data.groupby('domain').agg({'word_count': ['count', 'sum', 'mean']})\n",
    "stats.columns = ['post_count', 'word_count', 'avg_post_length']\n",
    "total = pd.DataFrame({'post_count': len(ws_data), 'word_count': ws_data.word_count.sum(), 'avg_post_length': ws_data.word_count.mean()}, index=['total'])\n",
    "display(pd.concat([stats,total]))\n",
    "\n",
    "# Load comparison corpora\n",
    "path = '../tmp/neutral_train_corpus.pkl'\n",
    "neutral_data = pd.read_pickle(path)\n",
    "neutral_data.info()\n",
    "\n",
    "# Post and word counts total and per domain\n",
    "stats = neutral_data.groupby('domain').agg({'word_count': ['count', 'sum', 'mean']})\n",
    "stats.columns = ['post_count', 'word_count', 'avg_post_length']\n",
    "total = pd.DataFrame({'post_count': len(neutral_data), 'word_count': neutral_data.word_count.sum(), 'avg_post_length': neutral_data.word_count.mean()}, index=['total'])\n",
    "display(pd.concat([stats,total]))\n",
    "\n",
    "# Load comparison corpora\n",
    "path = '../tmp/antiracist_train_corpus.pkl'\n",
    "antiracist_data = pd.read_pickle(path)\n",
    "antiracist_data.info()\n",
    "\n",
    "# Post and word counts total and per domain\n",
    "# data['word_count'] = data.text.str.split().str.len()\n",
    "stats = antiracist_data.groupby('domain').agg({'word_count': ['count', 'sum', 'mean']})\n",
    "stats.columns = ['post_count', 'word_count', 'avg_post_length']\n",
    "stats\n",
    "\n",
    "total = pd.DataFrame({'post_count': len(antiracist_data), 'word_count': antiracist_data.word_count.sum(), 'avg_post_length': antiracist_data.word_count.mean()}, index=['total'])\n",
    "total\n",
    "\n",
    "display(pd.concat([stats,total]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7063d63-4671-4149-9677-b65e49f4e006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8542705 entries, calderon2021_daily_stormer_1002 to medium_antiracist_4776\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Dtype              \n",
      "---  ------      -----              \n",
      " 0   corpus      object             \n",
      " 1   text        object             \n",
      " 2   word_count  int64              \n",
      " 3   dataset     object             \n",
      " 4   source      object             \n",
      " 5   domain      object             \n",
      " 6   timestamp   datetime64[ns, UTC]\n",
      " 7   topic       float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), int64(1), object(5)\n",
      "memory usage: 586.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>8140759</td>\n",
       "      <td>0.952949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antiracist</th>\n",
       "      <td>295843</td>\n",
       "      <td>0.034631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white_supremacist</th>\n",
       "      <td>106103</td>\n",
       "      <td>0.012420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    corpus    corpus\n",
       "neutral            8140759  0.952949\n",
       "antiracist          295843  0.034631\n",
       "white_supremacist   106103  0.012420"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([ws_data, neutral_data, antiracist_data], keys=['white_supremacist', 'neutral', 'antiracist'],\n",
    "                names=['corpus', 'id']).reset_index(level='corpus')\n",
    "data.info()\n",
    "\n",
    "pd.concat([data.corpus.value_counts(), data.corpus.value_counts(normalize=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f065c4eb-7c51-4a7c-bd07-f14b3929c5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reddit_match     6976057\n",
       "news_match       1088057\n",
       "twitter_match      52863\n",
       "discord_match      23782\n",
       "Name: dataset, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_data.dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc884b0-c52f-4277-912b-dce9d1b63cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.box(data[data.word_count<100], x='corpus', y='word_count')\n",
    "fig.update_traces(boxpoints=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254cba1e-2acc-4aee-8ed5-5f0e4faa63aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = 'plotly'\n",
    "selected = neutral_data.query('domain==\"forum\"')\n",
    "selected[selected.word_count<200].plot.hist(x='word_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45beea0b-c7d2-4a9f-84ec-1e5821d8972b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "papasavva2020       1901408\n",
       "stormfront           706232\n",
       "jokubausaite2020     415921\n",
       "ironmarch            148003\n",
       "qian2018              66294\n",
       "calderon2021          25685\n",
       "patriotfront          18739\n",
       "pruden2022            12351\n",
       "elsherief2021          4489\n",
       "Name: dataset, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d76055-18e8-45ea-9069-e83121f11119",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.groupby(['domain', 'dataset'])['text'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442097a0-3529-4611-833b-6b36ee54ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = data.groupby(['domain', 'dataset'])['text'].count().reset_index()\n",
    "counts = data.groupby(['domain', 'dataset'])['text'].count()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd16aa60-7c0f-47cc-bde8-ed500cebe826",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['domain', 'dataset', 'source'])['text'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b37361-ff76-46c8-971c-9d31cbba8e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't figure out how to sort wihin domains\n",
    "# counts.sort_values(['domain', 'dataset'], ascending=False).groupby('domain').groups()\n",
    "# counts.sort_values(['domain', 'dataset'], ascending=False).groupby('domain')['text'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9ca2b1-5c86-49a8-a69b-1a1fa1721527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num of posts from each dataset (maybe should do log scale)\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "vc = data.dataset.value_counts()\n",
    "print(vc)\n",
    "vc.plot.bar(text=vc.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494713d-fa60-41ee-abcd-fbefa36eccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num of posts from each dataset (maybe should do log scale)\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "vc = data.dataset.value_counts()\n",
    "print(vc)\n",
    "vc.plot.bar(text=vc.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662bba68-3819-48c5-b2cc-1605cf757cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of words\n",
    "data['num_words'] = data.text.str.split().str.len()\n",
    "# data.head()\n",
    "\n",
    "word_count =  data.groupby('dataset')['num_words'].sum()\n",
    "display(word_count)\n",
    "word_count.sort_values(ascending=False).plot.bar().show()\n",
    "\n",
    "# Total posts and words\n",
    "print(f'{len(data)} posts')\n",
    "print(f'{word_count.sum()} words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed123a4b-900c-4685-b901-2239697c7990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# By domain\n",
    "dataset_info = pd.DataFrame([\n",
    "    {'dataset': 'qian2018', 'domain': 'tweet/short propaganda'},\n",
    "    {'dataset': 'elsherief2021', 'domain': 'tweet/short propaganda'},\n",
    "    {'dataset': 'degibert2019', 'domain': 'forum'},\n",
    "    {'dataset': 'patriotfront', 'domain': 'chat'},\n",
    "    {'dataset': 'alatawi2021', 'domain': 'tweet/short propaganda'},\n",
    "    {'dataset': 'adl_heatmap', 'domain': 'tweet/short propaganda'},\n",
    "    {'dataset': 'ironmarch', 'domain': 'forum'},\n",
    "    {'dataset': '4chan', 'domain': 'forum'},\n",
    "    {'dataset': 'stormfront', 'domain': 'forum'},\n",
    "    {'dataset': 'calderon2021', 'domain': 'long-form'},\n",
    "    {'dataset': 'pruden2022', 'domain': 'long-form'},\n",
    "]).set_index('dataset')\n",
    "dataset_info\n",
    "\n",
    "# data.join(dataset_info, on='dataset').domain.value_counts().plot.bar(\n",
    "#     title=\"Number of posts by domain\", \n",
    "#     labels=dict(index='domain', value='number of posts'),\n",
    "# )\n",
    "\n",
    "vc = data.join(dataset_info, on='dataset').domain.value_counts()\n",
    "fig = px.bar(vc, title=\"Number of posts by domain\", \n",
    "       labels=dict(index='domain', value='number of posts'),\n",
    "        text = [f'{val}<br>{val/vc.sum(): .1%}' for val in vc.values],\n",
    "    )\n",
    "fig.update_layout(showlegend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6049a2e3-769e-4b0b-ba99-4e4a4c2a38e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = data.join(dataset_info, on='dataset').groupby('domain')['num_words'].sum().sort_values(ascending=False)\n",
    "fig = px.bar(num_words,\n",
    "    title=\"Number of words by domain\", \n",
    "    labels=dict(index='domain', value='number of words'),\n",
    "    text = [f'{val}<br>{val/num_words.sum(): .1%}' for val in num_words.values],\n",
    "       # log_y=True\n",
    "    )\n",
    "fig.update_layout(showlegend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8cdc9-9d4d-4e8c-8777-1ef7443a0302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate date ranges\n",
    "print(len(data))\n",
    "print(data.timestamp.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6f3c9f-3524-4293-94c1-87e300d22cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = 'plotly'\n",
    "data.timestamp.sample(int(1e6)).hist()\n",
    "# data.timestamp.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b95289-3a7a-4883-a42d-1c53b74e03aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp(year=2000, month=1, day=1, tz='utc')\n",
    "data.query('timestamp > @start_date').timestamp.sample(int(1e5)).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791893aa-bb72-4ce7-9afe-23fcbd226a10",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bin or group by month\n",
    "import plotly.express as px\n",
    "# pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "start_date = pd.Timestamp(year=2000, month=1, day=1, tz='utc')\n",
    "merged =  data.join(dataset_info, on='dataset').query('timestamp > @start_date').sample(int(1e6))\n",
    "# merged.hist(column='timestamp', by='domain')\n",
    "# merged.hist(column=['timestamp'])\n",
    "px.histogram(merged, x='timestamp', color='domain', barmode=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac189ce-3d84-4060-b7c2-9ac453f30098",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bin or group by month\n",
    "px.histogram(merged, x='timestamp', color='domain', barmode='overlay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea3538-5676-4986-b092-9d3724fd8376",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.histogram(data.query('domain==\"forum\"').sample(int(1e5)), x='timestamp', color='dataset', barmode='overlay')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
